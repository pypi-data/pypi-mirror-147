# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/00_tests/core/tst.compose.ipynb (unless otherwise specified).

__all__ = ['column_transformer_data_fixture', 'multi_split_data_fixture',
           'test_pipeline_find_last_fitted_model_seq_others', 'test_pipeline_find_last_fitted_model_parallel_2',
           'test_data_conversion_for_sequential_and_parallel', 'SimpleMultiComponent', 'test_multi_comp_io',
           'test_multi_comp_desc', 'test_athena_pipeline_training', 'test_multi_comp_hierarchy',
           'test_multi_comp_profiling', 'test_multi_comp_all_equal', 'test_multi_component_setters',
           'test_show_result_statistics', 'test_pass_components', 'test_chain_folders', 'test_set_root',
           'test_pass_functions_to_multi_component', 'Transform1', 'Transform2', 'SimplePipeline',
           'test_pipeline_fit_apply', 'test_pipeline_fit_apply_bis', 'test_pipeline_new_comp', 'test_pipeline_set_comp',
           'test_athena_pipeline_training', 'test_pipeline_load_estimator', 'build_pipeline_construct_diagram_1',
           'build_pipeline_construct_diagram_2', 'test_construct_diagram', 'test_show_summary', 'test_make_pipeline',
           'test_pipeline_factory', 'PandasTransformWithLabels1', 'PandasTransformWithLabels2', 'SimplePandasPipeline',
           'TransformWithLabels1', 'TransformWithLabels2', 'SimplePandasPipelineNoPandasComponent',
           'test_pandas_pipeline', 'test_parallel', 'test_pipeline_find_last_result',
           'test_pipeline_find_last_result_parallel1', 'test_pipeline_find_last_result_parallel2',
           'test_pipeline_find_last_result_parallel3', 'test_pipeline_find_last_fitted_model_seq',
           'test_pipeline_find_last_fitted_model_parallel', 'test_pipeline_find_last_fitted_model_parallel_remove',
           'TransformM', 'test_multi_modality', 'test_column_selector', 'test_concat', 'test_identity',
           'column_transformer_data', 'test_make_column_transformer', 'test_make_column_transformer_passthrough',
           'test_make_column_transformer_remainder', 'test_make_column_transformer_descendants',
           'test_make_column_transformer_fit_transform', 'Transform1', 'Transform2', 'multi_split_data',
           'test_multi_split_transform', 'test_multi_split_fit', 'test_multi_split_chain', 'test_multi_split_io',
           'test_multi_split_non_dict', 'test_multi_split_non_dict_bis', 'multi_split_data_df_column',
           'test_multi_split_df_column_transform', 'test_multi_split_df_column_fit']

# Cell
import pytest
import os
import joblib
from IPython.display import display
import pandas as pd
import numpy as np
import time
from pathlib import Path

from sklearn.preprocessing import StandardScaler
from sklearn.utils import Bunch
from sklearn.preprocessing import FunctionTransformer

from block_types.core.compose import *
from block_types.core.block_types import Component, PandasComponent, PickleSaverComponent
from block_types.core.utils import PickleIO
from block_types.utils.utils import remove_previous_results
from block_types.core.data_conversion import DataConverter, PandasConverter

import block_types.config.bt_defaults as dflt
from block_types.utils.utils import check_last_part

# Cell
@pytest.fixture (name='column_transformer_data')
def column_transformer_data_fixture():
    return column_transformer_data()

@pytest.fixture (name='multi_split_data')
def multi_split_data_fixture():
    return multi_split_data()

# Cell
from block_types.utils.dummies import make_pipe_fit1

def test_pipeline_find_last_fitted_model_seq_others ():
    path_results = 'test_pipeline_find_last_fitted_model_seq_start'
    remove_previous_results (path_results=path_results)

    # pipelines
    pipe1 = make_pipe_fit1 ()
    X = np.array([1,2,3]).reshape(-1,1)
    r1 = pipe1.fit_apply (X)

    # case 1: component A
    pipe2 = make_pipe_fit1 (path_results=path_results, verbose=2)
    r = pipe2.A.fit_apply (X)
    all_fitted = pipe2.find_last_fitted_model ()
    assert not all_fitted
    pipe2.A.raise_error = True
    with pytest.raises (RuntimeError):
        r2 = pipe2.fit_apply (None)
    remove_previous_results (path_results=path_results)

    # case 2: component B
    pipe2 = make_pipe_fit1 (path_results=path_results, verbose=2)
    r = pipe2.A.fit_apply (X)
    r = pipe2.B.fit_apply (r)
    all_fitted = pipe2.find_last_fitted_model ()
    assert not all_fitted
    pipe2.A.raise_error = True
    r2 = pipe2.fit_apply (None)
    assert (r1==r2).all()
    remove_previous_results (path_results=path_results)

    # case 2: component C
    pipe2 = make_pipe_fit1 (path_results=path_results, verbose=2)
    r = pipe2.A.fit_apply (X)
    r = pipe2.B.fit_apply (r)
    r = pipe2.C.fit_apply (r)
    all_fitted = pipe2.find_last_fitted_model ()
    assert not all_fitted
    pipe2.A.raise_error = True
    pipe2.B.raise_error = True
    pipe2.B.estimator = Bunch ()
    pipe2.C.estimator = Bunch ()
    r2 = pipe2.fit_apply (None)
    assert (r1==r2).all()
    remove_previous_results (path_results=path_results)

# Cell
from block_types.utils.dummies import make_pipe_fit2

def test_pipeline_find_last_fitted_model_parallel_2 ():
    path_results = 'test_pipeline_find_last_fitted_model_parallel_2'
    remove_previous_results (path_results=path_results)

    # ******************************************************
    # pipelines
    pipe1 = make_pipe_fit2 ()
    X = np.array([1,2,3]).reshape(-1,1)
    r1 = pipe1.fit_apply (X)

    # ******************************************************
    pipe2 = make_pipe_fit2 (path_results=path_results, verbose=2, root=True)
    # second
    r = pipe2.A0.fit_apply (X)
    r = pipe2.A1.fit_apply (r)
    b1 = pipe2.obj.B1.fit_apply (r)
    b2 = pipe2.obj.B2.fit_apply (r)

    b3a = pipe2.obj.B3a.fit_apply (r)
    b3b = pipe2.obj.B3b.fit_apply (b3a)
    b3c = pipe2.obj.B3c.fit_apply (b3b)
    b3d = pipe2.obj.B3d.fit_apply (b3c)

    b4a = pipe2.obj.B4a.fit_apply (r)
    b4b = pipe2.obj.B4b.fit_apply (b4a)
    b4c = pipe2.obj.B4c.fit_apply (b4b)
    b4d = pipe2.obj.B4d.fit_apply (b4c)
    b4e = pipe2.obj.B4e.fit_apply (b4d)

    b5 = pipe2.obj.B5.fit_apply (r)

    all_fitted = pipe2.find_last_fitted_model ()
    assert not all_fitted

    pipe2.A0.raise_error = True
    pipe2.A1.raise_error = True

    pipe2.obj.B3a.raise_error = True
    pipe2.obj.B3b.raise_error = True
    pipe2.obj.B3c.raise_error = True

    pipe2.obj.B4a.raise_error = True
    pipe2.obj.B4b.raise_error = True
    pipe2.obj.B4c.raise_error = True
    pipe2.obj.B4d.raise_error = True

    pipe2.A1.create_estimator()
    pipe2.obj.B2.create_estimator()
    pipe2.obj.B3a.create_estimator()
    pipe2.obj.B3b.create_estimator()
    pipe2.obj.B4b.create_estimator()
    pipe2.obj.B4c.create_estimator()
    pipe2.obj.B4e.create_estimator()
    pipe2.obj.B5.create_estimator()

    pipe2.logger.info (f'\n{"-"*100}\n')
    r2 = pipe2.fit_apply (None)
    assert (r1==r2).all()

    remove_previous_results (path_results=path_results)

    # ******************************************************

    pipe2.logger.info (f'\n{"*"*100}\n{"*"*100}\n')
    pipe2 = make_pipe_fit2 (path_results=path_results, verbose=2, root=True)
    # second
    r = pipe2.A0.fit_apply (X)
    r = pipe2.A1.fit_apply (r)
    b1 = pipe2.obj.B1.fit_apply (r)
    b2 = pipe2.obj.B2.fit_apply (r)

    b3a = pipe2.obj.B3a.fit_apply (r)
    b3b = pipe2.obj.B3b.fit_apply (b3a)
    b3c = pipe2.obj.B3c.fit_apply (b3b)
    b3d = pipe2.obj.B3d.fit_apply (b3c)

    b4 = pipe2.obj.pipeline_1_1.fit_apply (r)
    b5 = pipe2.obj.B5.fit_apply (r)

    all_fitted = pipe2.find_last_fitted_model ()
    assert not all_fitted

    pipe2.A0.raise_error = True
    pipe2.A1.raise_error = True

    pipe2.obj.B3a.raise_error = True
    pipe2.obj.B3b.raise_error = True
    pipe2.obj.B3c.raise_error = True

    pipe2.obj.B4a.raise_error = True
    pipe2.obj.B4b.raise_error = True
    pipe2.obj.B4c.raise_error = True
    pipe2.obj.B4d.raise_error = True

    pipe2.A1.create_estimator()
    pipe2.obj.B2.create_estimator()
    pipe2.obj.B3a.create_estimator()
    pipe2.obj.B3b.create_estimator()
    pipe2.obj.B4b.create_estimator()
    pipe2.obj.B4c.create_estimator()
    pipe2.obj.B4e.create_estimator()
    pipe2.obj.B5.create_estimator()

    pipe2.logger.info (f'\n{"-"*100}\n')
    r2 = pipe2.fit_apply (None)
    assert (r1==r2).all()

    remove_previous_results (path_results=path_results)

    # ******************************************************

    pipe2.logger.info (f'\n{"*"*100}\n{"*"*100}\n')
    pipe2 = make_pipe_fit2 (path_results=path_results, verbose=2, root=True)
    # second
    r = pipe2.A0.fit_apply (X)
    r = pipe2.A1.fit_apply (r)
    r = pipe2.obj.parallel.fit_apply (r)

    all_fitted = pipe2.find_last_fitted_model ()
    assert not all_fitted

    pipe2.A0.raise_error = True
    pipe2.A1.raise_error = True

    pipe2.obj.B1.raise_error = True
    pipe2.obj.B2.raise_error = True

    pipe2.obj.B3a.raise_error = True
    pipe2.obj.B3b.raise_error = True
    pipe2.obj.B3c.raise_error = True
    pipe2.obj.B3d.raise_error = True

    pipe2.obj.B4a.raise_error = True
    pipe2.obj.B4b.raise_error = True
    pipe2.obj.B4c.raise_error = True
    pipe2.obj.B4d.raise_error = True
    pipe2.obj.B4e.raise_error = True

    pipe2.obj.B5.raise_error = True

    pipe2.A1.create_estimator()
    pipe2.obj.B2.create_estimator()
    pipe2.obj.B3a.create_estimator()
    pipe2.obj.B3b.create_estimator()
    pipe2.obj.B4b.create_estimator()
    pipe2.obj.B4c.create_estimator()
    pipe2.obj.B4e.create_estimator()
    pipe2.obj.B5.create_estimator()

    pipe2.logger.info (f'\n{"-"*100}\n')
    r2 = pipe2.fit_apply (None)
    assert (r1==r2).all()

    remove_previous_results (path_results=path_results)

    # ******************************************************
    pipe2.logger.info (f'\n{"*"*100}\n{"*"*100}\n')
    pipe2 = make_pipe_fit2 (path_results=path_results, verbose=2, root=True, new_parallel=True)
    # second
    r = pipe2.A0.fit_apply (X)
    r = pipe2.A1.fit_apply (r)
    r = pipe2.obj.new_parallel.fit_apply (r)
    r = pipe2.C.fit_apply (r)

    all_fitted = pipe2.find_last_fitted_model ()
    assert not all_fitted

    pipe2.A0.raise_error = True
    pipe2.A1.raise_error = True

    pipe2.obj.B1.raise_error = True
    pipe2.obj.B2.raise_error = True

    pipe2.obj.B3a.raise_error = True
    pipe2.obj.B3b.raise_error = True
    pipe2.obj.B3c.raise_error = True
    pipe2.obj.B3d.raise_error = True

    pipe2.obj.B4a.raise_error = True
    pipe2.obj.B4b.raise_error = True
    pipe2.obj.B4c.raise_error = True
    pipe2.obj.B4d.raise_error = True
    pipe2.obj.B4e.raise_error = True

    pipe2.obj.B5.raise_error = True

    pipe2.new_parallel.raise_error = True

    pipe2.A1.create_estimator()
    pipe2.obj.B2.create_estimator()
    pipe2.obj.B3a.create_estimator()
    pipe2.obj.B3b.create_estimator()
    pipe2.obj.B4b.create_estimator()
    pipe2.obj.B4c.create_estimator()
    pipe2.obj.B4e.create_estimator()
    pipe2.obj.B5.create_estimator()

    pipe2.logger.info (f'\n{"-"*100}\n')
    r2 = pipe2.fit_apply (None)
    assert (r1==r2).all()

    remove_previous_results (path_results=path_results)

    # ******************************************************
    pipe2.logger.info (f'\n{"*"*100}\n{"*"*100}\n')
    pipe2 = make_pipe_fit2 (path_results=path_results, verbose=2, root=True, new_parallel=True)
    # second
    r = pipe2.A0.fit_apply (X)
    r = pipe2.A1.fit_apply (r)
    r = pipe2.obj.new_parallel.fit_apply (r)
    r = pipe2.C.fit_apply (r)
    r = pipe2.D.fit_apply (r)

    all_fitted = pipe2.find_last_fitted_model ()
    assert all_fitted

    pipe2.A0.raise_error = True
    pipe2.A1.raise_error = True

    pipe2.obj.B1.raise_error = True
    pipe2.obj.B2.raise_error = True

    pipe2.obj.B3a.raise_error = True
    pipe2.obj.B3b.raise_error = True
    pipe2.obj.B3c.raise_error = True
    pipe2.obj.B3d.raise_error = True

    pipe2.obj.B4a.raise_error = True
    pipe2.obj.B4b.raise_error = True
    pipe2.obj.B4c.raise_error = True
    pipe2.obj.B4d.raise_error = True
    pipe2.obj.B4e.raise_error = True

    pipe2.obj.B5.raise_error = True

    pipe2.new_parallel.raise_error = True
    pipe2.C.raise_error = True

    pipe2.A1.create_estimator()
    pipe2.obj.B2.create_estimator()
    pipe2.obj.B3a.create_estimator()
    pipe2.obj.B3b.create_estimator()
    pipe2.obj.B4b.create_estimator()
    pipe2.obj.B4c.create_estimator()
    pipe2.obj.B4e.create_estimator()
    pipe2.obj.B5.create_estimator()

    pipe2.D.create_estimator()

    pipe2.logger.info (f'\n{"-"*100}\n')
    r2 = pipe2.fit_apply (None)
    assert (r1==r2).all()

    remove_previous_results (path_results=path_results)

# Cell
from block_types.utils.dummies import (DataSource, SumXY, MaxOfPositiveWithSeparateLabels, Sum1direct,
                                       Multiply10direct, subtract_xy, MinOfPositiveWithoutSeparateLabels)

def test_data_conversion_for_sequential_and_parallel ():
    class SumXYConverter (DataConverter):
        def convert_before_transforming (self, X, **kwargs):
            self.label = X[2]
            return X[0], X[1]
        def convert_after_transforming (self, result, **kwargs):
            result['label'] = self.label
            return result

    pipe = Sequential (DataSource (),
                       SumXY (data_converter=SumXYConverter),
                       PandasComponent (apply=lambda X: X*2),
                       MaxOfPositiveWithSeparateLabels (data_converter='PandasConverter'),
                       Parallel (Sum1direct (data_converter='PandasConverter'),
                                 Multiply10direct (data_converter='PandasConverter'),
                                 finalize_result=lambda X: tuple(X)),
                       PandasComponent(apply=subtract_xy),
                       MinOfPositiveWithoutSeparateLabels (
                           data_converter=PandasConverter (separate_labels=False)),
                       make_column_transformer ((Multiply10direct (), ['a','b']),
                                                (Sum1direct (), ['c','d'])),
                       Sum1direct ())

    #result = pipe.fit_apply ()

# Comes from compose.ipynb, cell
class SimpleMultiComponent (MultiComponent):
    def __init__ (self, **kwargs):
        data_io = PickleIO (**kwargs)
        super().__init__(data_io=data_io,
                         **kwargs)

        self.tr1 = Component(FunctionTransformer (lambda x: x*3),
                             data_io=data_io,
                             name='tr1')
        self.tr2 = Component(FunctionTransformer (lambda x: x*2),
                             data_io=data_io,
                             name='tr2')

    def _apply (self, X):
        return self.tr1 (X) + self.tr2(X)

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_multi_comp_io ():
    path_results = 'multi_component_loading_saving'
    remove_previous_results (path_results=path_results)

    X = np.array([1,2,3])
    composition1 = SimpleMultiComponent (path_results=path_results)
    result1 = composition1 (X)

    composition2 = SimpleMultiComponent (path_results=path_results)
    result2 = composition2.data_io.load_result()
    assert (result1==result2).all()

    resut_tr1_2 = composition2.tr1.data_io.load_result()
    resut_tr2_2 = composition2.tr2.data_io.load_result()
    assert (resut_tr1_2==composition1.tr1(X)).all()
    assert (resut_tr2_2==composition1.tr2(X)).all()

    assert sorted(os.listdir (f'{path_results}/whole'))==['simple_multi_component_result.pk', 'tr1_result.pk', 'tr2_result.pk']

    composition1.set_split ('validation')
    result1b = composition1 (X)
    assert sorted(os.listdir (f'{path_results}/validation'))==['simple_multi_component_result.pk', 'tr1_result.pk', 'tr2_result.pk']

    remove_previous_results (path_results=f'{path_results}/whole')

    resut_tr1_2 = composition2.tr1.data_io.load_result(split='validation')
    resut_tr2_2 = composition2.tr2.data_io.load_result()

    assert (resut_tr1_2==composition1.tr1(X)).all()
    assert resut_tr2_2 is None

    composition2.set_split('validation')
    resut_tr1_2 = composition2.tr1.data_io.load_result()
    resut_tr2_2 = composition2.tr2.data_io.load_result()

    assert (resut_tr1_2==composition1.tr1(X)).all()
    assert (resut_tr2_2==composition1.tr2(X)).all()

    remove_previous_results (path_results=path_results)

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_multi_comp_desc ():
    class Intermediate (MultiComponent):
        def __init__ (self, name=None, **kwargs):
            super().__init__ (name=name, **kwargs)
            self.first = Component (name='first_component', **kwargs)
            self.second = Component (name='second_component', **kwargs)

    class Higher (MultiComponent):
        def __init__ (self, **kwargs):
            super().__init__ (**kwargs)
            self.first = Intermediate (name='first_intermediate', **kwargs)
            self.second = Intermediate (name='second_intermediate', **kwargs)
            self.gather_descendants(nick_name=False)

    higher = Higher()

    assert sorted(higher.obj.keys())==['first_component', 'first_intermediate', 'second_component', 'second_intermediate']

    # check types
    types = map(lambda x: type(x[1]), sorted(higher.obj.items()))
    assert list(types)==[list, Intermediate, list, Intermediate]

    sorted_list = list(sorted(higher.obj.items()))
    types = map(type, sorted_list[0][1])
    assert list(types)==[Component,Component]

    sorted_list = list(sorted(higher.obj.items()))
    types = map(type, sorted_list[2][1])
    assert list(types)==[Component,Component]

    sorted_keys=list(sorted(higher.cls.keys()))
    assert sorted_keys == ['Component', 'Intermediate']

    assert list(map(type,higher.cls[sorted_keys[0]]))==[Component, Component, Component, Component]

    assert list(map(type,higher.cls[sorted_keys[1]]))==[Intermediate, Intermediate]


    # ***********************
    # recursive behaviour: higher.first
    intermediate = higher.first
    assert sorted(intermediate.obj.keys())==['first_component', 'second_component']

    # check types
    types = map(lambda x: type(x[1]), sorted(intermediate.obj.items()))
    assert list(types)==[Component, Component]

    sorted_keys=list(sorted(intermediate.cls.keys()))
    assert sorted_keys==['Component']

    assert list(map(type,intermediate.cls[sorted_keys[0]]))==[Component,Component]

    # **********************************************
    # recursive behaviour: higher.second
    # **********************************************
    intermediate = higher.second
    assert sorted(intermediate.obj.keys())==['first_component', 'second_component']

    # check types
    types = map(lambda x: type(x[1]), sorted(intermediate.obj.items()))
    assert list(types)==[Component, Component]

    sorted_keys=list(sorted(intermediate.cls.keys()))
    assert sorted_keys==['Component']

    assert list(map(type,intermediate.cls[sorted_keys[0]]))==[Component,Component]

    # **********************************************
    # full hierarchical paths
    # **********************************************
    assert list(sorted(higher.full_cls.keys()))==['Component', 'Intermediate']
    assert higher.full_cls['Intermediate']==['higher.first_intermediate', 'higher.second_intermediate']
    assert higher.full_cls['Component']==['higher.first_intermediate.first_component',
      'higher.first_intermediate.second_component',
      'higher.second_intermediate.first_component',
      'higher.second_intermediate.second_component']

    assert higher.first.full_cls['Component']==['higher.first_intermediate.first_component',
      'higher.first_intermediate.second_component']

    assert list(sorted(higher.full_obj))==['first_component', 'first_intermediate', 'second_component', 'second_intermediate']

    assert higher.full_obj['first_intermediate']=='higher.first_intermediate'

    assert higher.full_obj['first_component']==['higher.first_intermediate.first_component',
      'higher.second_intermediate.first_component']

    assert higher.full_obj['second_component']==['higher.first_intermediate.second_component',
      'higher.second_intermediate.second_component']

    assert higher.full_obj['second_intermediate']=='higher.second_intermediate'

    assert list(sorted(higher.second.full_obj))==['first_component', 'second_component']

    assert higher.second.full_obj['first_component']=='higher.second_intermediate.first_component'

    assert higher.second.full_obj['second_component']=='higher.second_intermediate.second_component'

    assert higher.hierarchy_path=='higher'

    assert higher.first.hierarchy_path=='higher.first_intermediate'

    # with nick_names
    higher.clear_descendants()
    higher.gather_descendants(nick_name=True)

    assert higher.full_cls['Component']==['higher.first.first',
     'higher.first.second',
     'higher.second.first',
     'higher.second.second']

    assert higher.full_obj['first_intermediate']=='higher.first'
    assert higher.full_obj['first_component']==['higher.first.first', 'higher.second.first']
    assert higher.full_obj['second_component']==['higher.first.second', 'higher.second.second']
    assert higher.full_obj['second_intermediate']=='higher.second'

    #Check that we always have attributes for each component name
    assert higher.first_intermediate is higher.first
    assert higher.second_intermediate is higher.second
    assert higher.components==[higher.first, higher.second]

    #check that set_components and add_component create self attrs called
    # the same as the component

    class Higher (MultiComponent):
        def __init__ (self, **kwargs):
            super().__init__ (**kwargs)
            self.set_components (Intermediate (name='first_intermediate', **kwargs),
                                 Intermediate (name='second_intermediate', **kwargs))
    higher = Higher()

    assert higher.components == (higher.first_intermediate, higher.second_intermediate)

    class Higher (MultiComponent):
        def __init__ (self, **kwargs):
            super().__init__ (**kwargs)
            self.add_component (Intermediate (name='first_intermediate', **kwargs))
            self.add_component (Intermediate (name='second_intermediate', **kwargs))
    higher = Higher()

    assert higher.components == [higher.first_intermediate, higher.second_intermediate]

# Comes from compose.ipynb, cell
# second example
# **********************************************
# exports tests.core.test_compose
#@pytest.mark.reference_fails
def test_athena_pipeline_training ():
    class Intermediate (MultiComponent):
        def __init__ (self, name=None, **kwargs):
            super().__init__ (name=name, **kwargs)
            self.first = Component (name=f'{name}_first_component', **kwargs)
            self.second = Component (name=f'{name}_second_component', **kwargs)

    class Higher (MultiComponent):
        def __init__ (self, **kwargs):
            super().__init__ (**kwargs)
            self.first = Intermediate (name='first_intermediate', **kwargs)
            self.second = Intermediate (name='second_intermediate', **kwargs)
            self.gather_descendants(nick_name=False)

    higher = Higher()

    assert sorted(higher.obj.keys())==['first_intermediate', 'first_intermediate_first_component', 'first_intermediate_second_component', 'second_intermediate', 'second_intermediate_first_component', 'second_intermediate_second_component']

    # check types
    types = map(lambda x: type(x[1]), sorted(higher.obj.items()))

    assert list(types)==[Intermediate, Component, Component, Intermediate, Component, Component]

    sorted_keys=list(sorted(higher.cls.keys()))
    assert sorted_keys == ['Component', 'Intermediate']

    assert list(map(type,higher.cls[sorted_keys[0]]))==[Component, Component, Component, Component]
    assert list(map(type,higher.cls[sorted_keys[1]]))==[Intermediate, Intermediate]

    # ***********************
    # recursive behaviour: higher.first
    intermediate = higher.first
    assert sorted(intermediate.obj.keys())==['first_intermediate_first_component', 'first_intermediate_second_component']

    # check types
    types = map(lambda x: type(x[1]), sorted(intermediate.obj.items()))
    assert list(types)==[Component, Component]

    sorted_keys=list(sorted(intermediate.cls.keys()))
    assert sorted_keys==['Component']

    assert list(map(type,intermediate.cls[sorted_keys[0]]))==[Component,Component]

    # ***********************
    # recursive behaviour: higher.second
    intermediate = higher.second
    assert sorted(intermediate.obj.keys())==['second_intermediate_first_component', 'second_intermediate_second_component']

    # check types
    types = map(lambda x: type(x[1]), sorted(intermediate.obj.items()))
    assert list(types)==[Component, Component]

    sorted_keys=list(sorted(intermediate.cls.keys()))
    assert sorted_keys==['Component']

    assert list(map(type,intermediate.cls[sorted_keys[0]]))==[Component,Component]


    # **********************************************
    # full hierarchical paths
    # **********************************************
    assert list(sorted(higher.full_cls))==['Component', 'Intermediate']

    assert higher.full_cls['Component']==['higher.first_intermediate.first_intermediate_first_component',
      'higher.first_intermediate.first_intermediate_second_component',
      'higher.second_intermediate.second_intermediate_first_component',
      'higher.second_intermediate.second_intermediate_second_component']

    assert higher.full_cls['Intermediate']==['higher.first_intermediate', 'higher.second_intermediate']

    assert list(higher.first.full_cls)==['Component']

    assert higher.first.full_cls['Component']==['higher.first_intermediate.first_intermediate_first_component',
      'higher.first_intermediate.first_intermediate_second_component']

    assert sorted(list(higher.full_obj))==['first_intermediate',
     'first_intermediate_first_component',
     'first_intermediate_second_component',
     'second_intermediate',
     'second_intermediate_first_component',
     'second_intermediate_second_component']

    assert higher.full_obj['first_intermediate']=='higher.first_intermediate'

    assert higher.full_obj['first_intermediate_first_component']=='higher.first_intermediate.first_intermediate_first_component'

    assert higher.full_obj['first_intermediate_second_component']=='higher.first_intermediate.first_intermediate_second_component'

    assert higher.full_obj['second_intermediate']=='higher.second_intermediate'

    assert higher.full_obj['second_intermediate_first_component']=='higher.second_intermediate.second_intermediate_first_component'

    assert higher.full_obj['second_intermediate_second_component']=='higher.second_intermediate.second_intermediate_second_component'

    assert list(sorted(higher.second.full_obj))==['second_intermediate_first_component', 'second_intermediate_second_component']

    assert higher.second.full_obj['second_intermediate_first_component']=='higher.second_intermediate.second_intermediate_first_component'

    assert higher.second.full_obj['second_intermediate_second_component']=='higher.second_intermediate.second_intermediate_second_component'

    assert higher.hierarchy_path=='higher'

    assert higher.first.hierarchy_path=='higher.first_intermediate'

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_multi_comp_hierarchy ():
    class Intermediate (MultiComponent):
        def __init__ (self, name=None, z=6, h=10, x=3, **kwargs):
            super().__init__ (name=name, **kwargs)
            self.first = Component (name='first_component', **kwargs)
            self.second = Component (name='second_component', **kwargs)

    class Higher (MultiComponent):
        def __init__ (self, x=2, y=3, **kwargs):
            super().__init__ (**kwargs)
            self.first = Intermediate (name='first_intermediate', **kwargs)
            self.second = Intermediate (name='second_intermediate', **kwargs)
            self.gather_descendants()

    higher = Higher()

    levels=dict(
        until=1,
        verbose=1
    )
    higher = Higher (levels=levels, verbose=0)

    assert higher.hierarchy_level==0 and higher.first.hierarchy_level==1 and higher.first.first.hierarchy_level==2

    assert higher.verbose==1 and higher.first.verbose==1 and higher.first.first.verbose==0

    levels['until']=0
    higher = Higher (levels=levels, verbose=0)
    assert higher.verbose==1 and higher.first.verbose==0 and higher.first.first.verbose==0

    levels['until']=2
    higher = Higher (levels=levels, verbose=0)
    assert higher.verbose==1 and higher.first.verbose==1 and higher.first.first.verbose==1

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_multi_comp_profiling ():
    class A(Component):
        def __init__ (self, time=1, **kwargs):
            super().__init__(**kwargs)

        def _fit (self, X, y=None):
            time.sleep(self.time*2)

        def _apply (self, X):
            time.sleep(self.time)
            return 1

    class Intermediate (MultiComponent):
        def __init__ (self, name=None, **kwargs):
            super().__init__ (name=name, **kwargs)
            self.first = A (name=f'{name}_first_component', time=0.01, **kwargs)
            self.second = A (name=f'{name}_second_component', time=0.03, **kwargs)
        def _fit (self, X, y=None):
            self.first.fit (X,y)
            self.second.fit (X,y)
        def _apply (self, X):
            _ = self.first.apply (X)
            _ = self.second.apply (X)
            return 1

    class Higher (MultiComponent):
        def __init__ (self, **kwargs):
            super().__init__ (**kwargs)
            self.first = Intermediate (name='first', **kwargs)
            self.second = Intermediate (name='second', **kwargs)
        def _fit (self, X, y=None):
            self.first.fit (X,y)
            self.second.fit (X,y)
        def _apply (self, X):
            _ = self.first.apply (X)
            _ = self.second.apply (X)
            return 1

    higher = Higher()
    higher.fit (1)
    _ = higher.apply (1)
    dfd = higher.gather_times()

    values = dfd.avg[('whole','apply')].values
    assert np.abs(values[1:3].sum() - values[0]) < 0.05
    assert np.abs(values[3:5].sum() - values[1]) < 0.05
    assert np.abs(values[5:7].sum() - values[2]) < 0.05

    values = dfd.avg[('whole','fit')].values
    assert np.abs(values[1:3].sum() - values[0]) < 0.05
    assert np.abs(values[3:5].sum() - values[1]) < 0.05
    assert np.abs(values[5:7].sum() - values[2]) < 0.05

    display('avg', dfd.avg)

    assert (dfd.novh_avg <= dfd.avg).all().all()
    assert (dfd.novh_avg < dfd.avg).any().any()

    assert ((dfd.novh_avg.iloc[-4:].sum(axis=0).to_frame().T) == dfd.no_overhead_total).all(axis=1).all()

    assert ((dfd.avg.iloc[0]-dfd.novh_avg.iloc[-4:].sum(axis=0)).values == dfd.overhead_total.values).all()

    display('no_overhead_total', dfd.no_overhead_total)
    display('overhead_total', dfd.overhead_total)

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_multi_comp_all_equal ():
    path_results = 'multi_component_assert_equal'
    remove_previous_results (path_results=path_results)

    # 1. by setting components as attributes:
    class NewComposition(MultiComponent):

        def __init__ (self, noise = 0, **kwargs):
            super().__init__(**kwargs)

            self.tr1 = Component(FunctionTransformer (lambda x: x*3 + noise),
                                 name='tr1',
                                 **kwargs)
            self.tr2 = Component(FunctionTransformer (lambda x: x*2),
                                 name='tr2',
                                 **kwargs)

        def _apply (self, X):
            return self.tr1 (X) + self.tr2(X)

    X = np.array([1,2,3])

    composition1 = NewComposition (path_results=path_results)
    result1 = composition1 (X)

    path_results2 = 'multi_component_assert_equal_2'
    remove_previous_results (path_results=path_results2)
    composition2 = NewComposition (path_results=path_results2)
    result2 = composition2 (X)
    assert composition1.assert_all_equal (path_results2)

    remove_previous_results (path_results=path_results2)
    composition2 = NewComposition (path_results=path_results2, noise=0.1)
    result2 = composition2 (X)
    assert not composition1.assert_all_equal (path_results2)

    # *************************
    # check verbosity
    # *************************
    composition1 = NewComposition (path_results=path_results, verbose=1)
    composition1.logger.info ('\n******************************')
    composition1.logger.info ('verbose')
    composition1.logger.info ('******************************')
    assert not composition1.assert_all_equal (path_results2)

    composition1.logger.info ('\n******************************')
    composition1.logger.info ('not verbose')
    composition1.logger.info ('******************************')
    assert not composition1.assert_all_equal (path_results2, verbose=0)
    composition1.logger.info ('logger works again')

    # *******************************
    # check recursion
    # *******************************
    class NewComposition (MultiComponent):

        def __init__ (self, noise = 0, **kwargs):
            super().__init__(**kwargs)

            self.tr1 = Component(FunctionTransformer (lambda x: x*2 + noise),
                                 name='tr1',
                                 **kwargs)
            self.tr2 = Component(FunctionTransformer (lambda x: x*3),
                                 name='tr2',
                                 **kwargs)

        def _apply (self, X):
            return self.tr1 (X) + self.tr2(X)

    path_results3 = 'multi_component_assert_equal_3'
    composition3 = NewComposition (path_results=path_results3)
    result3 = composition3 (X)
    assert not composition3.assert_all_equal (path_results)
    assert composition3.assert_all_equal (path_results, max_recursion=0)
    assert not composition3.assert_all_equal (path_results, max_recursion=1)

    class NewComposition (MultiComponent):

        def __init__ (self, noise = 0, **kwargs):
            super().__init__(**kwargs)

            self.tr1 = Component(FunctionTransformer (lambda x: x*4 + noise),
                                 name='tr1',
                                 **kwargs)
            self.tr2 = Component(FunctionTransformer (lambda x: x*5),
                                 name='tr2',
                                 **kwargs)

        def _apply (self, X):
            return self.tr1 (X) + self.tr2(X)

    remove_previous_results (path_results=path_results3)
    composition4 = NewComposition (path_results=path_results3)
    result3 = composition4 (X)
    assert not composition4.assert_all_equal (path_results)
    assert not composition4.assert_all_equal (path_results, max_recursion=0)
    assert not composition4.assert_all_equal (path_results, max_recursion=1)

    # *************************
    # remove results
    # *************************
    remove_previous_results (path_results=path_results)
    remove_previous_results (path_results=path_results2)
    remove_previous_results (path_results=path_results3)

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_multi_component_setters ():
    multi_component = SimpleMultiComponent ()

    all_true = lambda x: all([x.data_io.save_splits[k] for k in x.data_io.save_splits])
    assert all_true (multi_component)

    c0, c1 = multi_component.components[0], multi_component.components[1]

    assert all_true (c0) and all_true (c1)

    multi_component.set_save_splits ({'training': True, 'test': False, 'validation': False, 'whole': True})

    tv_false = lambda x: (all ([x.data_io.save_splits[k] for k in ['training', 'whole']])
                          and all ([(not x.data_io.save_splits[k]) for k in ['test', 'validation']]))
    assert tv_false(c0) and tv_false (c1) and tv_false (multi_component)

    cond = lambda x: x.data_io.load_model_flag
    assert cond (c0) and cond (c1) and cond (multi_component)

    multi_component.set_load_model (False)
    cond = lambda x: not x.data_io.load_model_flag
    assert cond (c0) and cond (c1) and cond (multi_component)

    cond = lambda x: x.data_io.save_model_flag
    assert cond (c0) and cond (c1) and cond (multi_component)

    multi_component.set_save_model (False)
    cond = lambda x: not x.data_io.save_model_flag
    assert cond (c0) and cond (c1) and cond (multi_component)

    #set_save_result
    cond = lambda x: x.data_io.save_result_flag
    assert cond (c0) and cond (c1) and cond (multi_component)

    multi_component.set_save_result (False)
    cond = lambda x: not x.data_io.save_result_flag
    assert cond (c0) and cond (c1) and cond (multi_component)

    # set_load_result
    cond = lambda x: x.data_io.load_result_flag
    assert cond (c0) and cond (c1) and cond (multi_component)

    multi_component.set_load_result (False)
    cond = lambda x: not x.data_io.load_result_flag
    assert cond (c0) and cond (c1) and cond (multi_component)

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_show_result_statistics ():
    path_results = 'show_result_statistics'
    remove_previous_results (path_results=path_results)
    multi_component = SimpleMultiComponent (path_results=path_results)
    X=np.array([1,2,3])
    r = multi_component(X)
    multi_component.show_result_statistics();

    remove_previous_results (path_results=path_results)
    X=pd.DataFrame({'a':[4,5,6], 'b':[7,8,9]})
    r = multi_component(X)
    multi_component.show_result_statistics();
    remove_previous_results (path_results=path_results)

# Comes from compose.ipynb, cell
def test_pass_components ():
    config = dict (path_results='my_path', Second=dict(path_results='other_path'))
    multi = MultiComponent (Component (name='first', class_name='First', folder='one', **config),
                            Component (name='second', class_name='Second', folder='two', **config),
                            name='Inner',
                            **config)

    check_last_part (multi.path_results, 'my_path')
    check_last_part (multi.second.path_results, 'other_path')
    check_last_part (multi.first.path_results, 'my_path')

    assert multi.first.data_io.folder=='one'
    assert multi.second.data_io.folder=='two'

    def make_inner (folder, name, **kwargs):
        return MultiComponent (Component (name='first', class_name='First', folder='folder_first', **kwargs),
                               Component (name='second', class_name='Second', folder='folder_second', **kwargs),
                               folder=folder,
                               class_name='Inner',
                               name=name,
                               **kwargs)
    multi = MultiComponent (make_inner ('one', 'inner1', **config), make_inner ('two', 'inner2', **config), **config)

    check_last_part (multi.inner1.first.data_io.get_path_result_file(),
        'my_path/one/folder_first/whole/first_result.pk')

    check_last_part (multi.inner1.second.data_io.get_path_result_file(),
        'other_path/one/folder_second/whole/second_result.pk')

    check_last_part (multi.inner2.first.data_io.get_path_result_file(),
        'my_path/two/folder_first/whole/first_result.pk')

    check_last_part (multi.inner2.second.data_io.get_path_result_file(),
        'other_path/two/folder_second/whole/second_result.pk')

    config = dict (path_results='my_path', Inner=dict(path_results='other_path'))
    def make_inner (folder, name, **kwargs):
        return MultiComponent (Component (name='first', class_name='First', folder='folder_first', **kwargs),
                               Component (name='second', class_name='Second', folder='folder_second', **kwargs),
                               folder=folder,
                               class_name='Inner',
                               name=name,
                               **kwargs)
    multi = MultiComponent (make_inner ('one', 'inner1', **config),
                            make_inner ('two', 'inner2', **config),
                            folder='__class__',
                            class_name='Higher',
                            name='higher',
                            **config)

    check_last_part (multi.inner1.first.data_io.get_path_result_file(),
        'my_path/higher/one/folder_first/whole/first_result.pk')

    check_last_part (multi.inner1.second.data_io.get_path_result_file(),
        'my_path/higher/one/folder_second/whole/second_result.pk')

    check_last_part (multi.inner2.first.data_io.get_path_result_file(),
        'my_path/higher/two/folder_first/whole/first_result.pk')

    check_last_part (multi.inner2.second.data_io.get_path_result_file(),
        'my_path/higher/two/folder_second/whole/second_result.pk')

    check_last_part (multi.inner1.data_io.get_path_result_file(),
        'other_path/higher/one/whole/inner1_result.pk')

    check_last_part (multi.inner2.data_io.get_path_result_file(),
        'other_path/higher/two/whole/inner2_result.pk')

    multi = MultiComponent (make_inner ('one', 'inner1', **config, propagate=True),
                            make_inner ('two', 'inner2', **config, propagate=True),
                            folder='__class__',
                            class_name='Higher',
                            name='higher',
                            **config)

    check_last_part (multi.inner1.first.data_io.get_path_result_file(),
        'other_path/higher/one/folder_first/whole/first_result.pk')

    check_last_part (multi.inner1.second.data_io.get_path_result_file(),
                     'other_path/higher/one/folder_second/whole/second_result.pk')

    check_last_part (multi.inner2.first.data_io.get_path_result_file(),
                     'other_path/higher/two/folder_first/whole/first_result.pk')

    check_last_part (multi.inner2.second.data_io.get_path_result_file(),
                     'other_path/higher/two/folder_second/whole/second_result.pk')

    check_last_part (multi.inner1.data_io.get_path_result_file(),
                     'other_path/higher/one/whole/inner1_result.pk')

    check_last_part (multi.inner2.data_io.get_path_result_file(),
                     'other_path/higher/two/whole/inner2_result.pk')

    check_last_part (multi.data_io.get_path_result_file(),
                     'my_path/higher/whole/higher_result.pk')

    multi = MultiComponent (make_inner ('one', 'inner1', **config),
                            make_inner ('two', 'inner2', **config),
                            folder='__class__',
                            class_name='Higher',
                            name='higher',
                            propagate=True,
                            **config)

    check_last_part (multi.inner1.first.data_io.get_path_result_file(),
                     'my_path/higher/one/folder_first/whole/first_result.pk')

    check_last_part (multi.inner1.second.data_io.get_path_result_file(),
                     'my_path/higher/one/folder_second/whole/second_result.pk')

    check_last_part (multi.inner2.first.data_io.get_path_result_file(),
                     'my_path/higher/two/folder_first/whole/first_result.pk')

    check_last_part (multi.inner2.second.data_io.get_path_result_file(),
                     'my_path/higher/two/folder_second/whole/second_result.pk')

    check_last_part (multi.inner1.data_io.get_path_result_file(),
                     'my_path/higher/one/whole/inner1_result.pk')

    check_last_part (multi.inner2.data_io.get_path_result_file(),
                     'my_path/higher/two/whole/inner2_result.pk')

    check_last_part (multi.data_io.get_path_result_file(),
                     'my_path/higher/whole/higher_result.pk')

    config = dict (path_results='my_path', Inner=dict(path_results='other_path', stop_propagation=True))
    multi = MultiComponent (make_inner ('one', 'inner1', **config, propagate=True),
                            make_inner ('two', 'inner2', **config, propagate=True),
                            folder='__class__',
                            class_name='Higher',
                            name='higher',
                            propagate=True,
                            **config)

    check_last_part (multi.inner1.first.data_io.get_path_result_file(),
                     'other_path/higher/one/folder_first/whole/first_result.pk')

    check_last_part (multi.inner1.second.data_io.get_path_result_file(),
                     'other_path/higher/one/folder_second/whole/second_result.pk')

    check_last_part (multi.inner2.first.data_io.get_path_result_file(),
                     'other_path/higher/two/folder_first/whole/first_result.pk')

    check_last_part (multi.inner2.second.data_io.get_path_result_file(),
                     'other_path/higher/two/folder_second/whole/second_result.pk')

    check_last_part (multi.inner1.data_io.get_path_result_file(),
                     'other_path/higher/one/whole/inner1_result.pk')

    check_last_part (multi.inner2.data_io.get_path_result_file(),
                     'other_path/higher/two/whole/inner2_result.pk')

    check_last_part (multi.data_io.get_path_result_file(),
                     'my_path/higher/whole/higher_result.pk')

# Comes from compose.ipynb, cell
def test_chain_folders ():
    config = dict (path_results='my_path', Second=dict(path_results='other_path'))
    def first_level ():
        a0=Component (name='first', class_name='First', folder='folder_first', **config)
        b0=Component (name='second', class_name='Second', folder='folder_second', **config)
        return a0, b0

    a0, b0 = first_level()

    assert a0.data_io.folder=='folder_first'

    def second_level ():
        a0, b0 = first_level ()
        a1= MultiComponent (a0, b0, folder='one', class_name='Inner', name='inner1', **config)
        a0, b0 = first_level ()
        b1= MultiComponent (a0, b0, folder='two', class_name='Inner', name='inner2', **config)
        return a1, b1

    a1, b1 = second_level ()

    assert a1.first.data_io.folder=='one/folder_first'
    assert a1.second.data_io.folder=='one/folder_second'
    assert b1.first.data_io.folder=='two/folder_first'
    assert b1.second.data_io.folder=='two/folder_second'

    def third_level ():
        a1, b1 = second_level ()
        a2= MultiComponent (a1, b1, folder='third1', class_name='Higher', name='higher1', **config)
        a1, b1 = second_level ()
        b2= MultiComponent (a1, b1, folder='third2', class_name='Higher', name='higher2', **config)
        return a2, b2

    a2, b2 = third_level ()

    assert a2.inner1.first.data_io.folder=='third1/one/folder_first'
    assert a2.inner1.second.data_io.folder=='third1/one/folder_second'
    assert b2.inner1.first.data_io.folder=='third2/one/folder_first'
    assert b2.inner1.second.data_io.folder=='third2/one/folder_second'
    assert b2.inner2.first.data_io.folder=='third2/two/folder_first'
    assert b2.inner2.second.data_io.folder=='third2/two/folder_second'

# Comes from compose.ipynb, cell
def test_set_root ():
    config = dict (path_results='my_path', Second=dict(path_results='other_path'))
    def first_level ():
        a0=Component (name='first', class_name='First', folder='folder_first', **config)
        b0=Component (name='second', class_name='Second', folder='folder_second', **config)
        return a0, b0

    a0, b0 = first_level()

    def second_level ():
        a0, b0 = first_level ()
        a1= MultiComponent (a0, b0, folder='one', class_name='Inner', name='inner1', **config)
        a0, b0 = first_level ()
        b1= MultiComponent (a0, b0, folder='two', class_name='Inner', name='inner2', **config)
        return a1, b1

    a1, b1 = second_level ()

    def third_level ():
        a1, b1 = second_level ()
        a2= MultiComponent (a1, b1, folder='third1', class_name='Higher', name='higher1', **config)
        a1, b1 = second_level ()
        b2= MultiComponent (a1, b1, folder='third2', class_name='Higher', name='higher2', **config)
        return a2, b2

    a2, b2 = third_level ()
    c = MultiComponent (a2, b2)
    assert [x.name for x in c.higher1.inner1.components] == ['first', 'second']
    assert [x.name for x in c.higher1.inner2.components] == ['first', 'second']

    c = MultiComponent (a2, b2, root=True)
    assert [x.name for x in c.higher1.inner1.components] == ['first', 'second']
    assert [x.name for x in c.higher1.inner2.components] == ['first_1', 'second_1']
    assert [x.data_io.fitting_file_name for x in c.higher1.inner2.components] == ['first_1_estimator.pk', 'second_1_estimator.pk']
    assert [x.data_io.result_file_name for x in c.higher1.inner2.components] == ['first_1_result.pk', 'second_1_result.pk']

# Comes from compose.ipynb, cell
from block_types.utils.dummies import Sum1, DummyEstimator

def test_pass_functions_to_multi_component ():
    def myf (x): return x*2
    pipe = MultiComponent (Sum1 (), myf, lambda x: x+3, ('Minus', lambda x: x-1), DummyEstimator () )
    X = np.array ([1,2,3])
    r = X
    pipe.components[-1].fit (X)
    for c in pipe.components:
        r = c (r)
    assert (r== ( ((X+1)*2+3-1)*3+X.sum() )).all()
    class_names = ['Sum1', 'Myf', '<Lambda>', 'Minus', 'DummyEstimator']
    assert all([x.class_name==y for x, y in zip(pipe.components, class_names)])

# Comes from compose.ipynb, cell
class Transform1 (Component):

    def __init__ (self, **kwargs):
        super().__init__ (**kwargs)
        self.estimator = Bunch(sum = 1)

    def _fit (self, X, y=None):
        self.estimator.sum = X.sum(axis=0)

    def _apply (self, x):
        return x*1000 + self.estimator.sum

class Transform2 (Component):

    def __init__ (self, **kwargs):
        super().__init__ (**kwargs)
        self.estimator = Bunch(maxim = 1)

    def _fit (self, X, y=None):
        self.estimator.maxim = X.max(axis=0)

    def _apply (self, x):
        return x*100 + self.estimator.maxim

class SimplePipeline (Pipeline):
    def __init__ (self, **kwargs):
        super().__init__ (**kwargs)

        # custom transform
        self.tr1 = Transform1(**kwargs)

        # slklearn transform
        self.tr2 = Transform2(**kwargs)

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_pipeline_fit_apply ():
    # test `fit_apply` method
    pipeline = SimplePipeline()
    x = np.array([3,4,5])
    r1 = pipeline.fit_apply (x.reshape(-1,1))
    print (r1)

    x1 = x * 1000 + sum(x)
    x2 = x1 * 100 + max(x1)
    assert (r1.ravel()==x2).all()

    # *********************************
    # Another way of building a pipeline
    # *********************************
    pipeline = Sequential (Transform1(),
                           Transform2())

    x = np.array([3,4,5])
    r1 = pipeline.fit_apply (x.reshape(-1,1))

    x1 = x * 1000 + sum(x)
    x2 = x1 * 100 + max(x1)
    assert (r1.ravel()==x2).all()

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_pipeline_fit_apply_bis ():
    # test `fit_apply` method
    class NewMulti (MultiComponent):

        def __init__ (self, **kwargs):
            super().__init__ (**kwargs)

            # custom transform
            self.tr1 = Transform1(**kwargs)

            # slklearn transform
            self.tr2 = Transform2(**kwargs)

        def _fit (self, X, y=None):
            self.tr1.fit (X)
            self.tr2.fit (X)

        def _apply (self, X, y=None):
            X1=self.tr1.apply (X)
            X2=self.tr2.apply (X)
            return X1+X2

    new_multi = NewMulti()
    x = np.array([3,4,5])
    r2 = new_multi.fit_apply (x)
    print (r2)

    x2b = 100 * x + max(x)
    x1 = x * 1000 + sum(x)
    assert (r2.ravel()==(x1 + x2b)).all()

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_pipeline_new_comp ():
    # test automatic creation of pipeline components

    # 1. by setting components as attributes:
    class NewPipeline(Pipeline):
        def __init__ (self, **kwargs):
            super().__init__(**kwargs)
            self.tr1 = Component(FunctionTransformer (lambda x: x+1))
            self.tr2 = Component(FunctionTransformer (lambda x: x*2))
    pipeline = NewPipeline()
    result = pipeline.transform (3)
    print (result)
    assert result == 8

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_pipeline_set_comp ():
    #2. by using `set_components`
    class NewPipeline(Pipeline):
        def __init__ (self, **kwargs):
            super().__init__(**kwargs)
            tr1 = Component(FunctionTransformer (lambda x: x+1))
            tr2 = Component(FunctionTransformer (lambda x: x*2))
            self.set_components (tr1, tr2)

            # the following transform is not added to the pipeline component list:
            self.tr3 = Component(FunctionTransformer (lambda x: x+1))

            # The reason is that once set_components is called, the component list
            # is frozen and inmutable setting new components by attribute doesn't
            # result in adding them to the component list

    pipeline = NewPipeline()
    result = pipeline.transform (3)

    assert result == 8
    assert len(pipeline.components) == 2
    print (result, len(pipeline.components))

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_athena_pipeline_training ():
#3. after calling `set_components()`, we can add new components with `add_component()`
    class NewPipeline(Pipeline):
        def __init__ (self, **kwargs):
            super().__init__(**kwargs)
            tr1 = Component(FunctionTransformer (lambda x: x+1))
            tr2 = Component(FunctionTransformer (lambda x: x*2))
            self.set_components (tr1, tr2)

            tr3 = Component(FunctionTransformer (lambda x: x+2))
            self.add_component(tr3)

    pipeline = NewPipeline()
    result = pipeline.transform (3)

    assert result == 10
    assert len(pipeline.components) == 3
    print (result, len(pipeline.components))

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_pipeline_load_estimator ():
    # test `load_estimator` method

    # Transform1: custom Transform
    class Transform1 (PickleSaverComponent):

        def __init__ (self, **kwargs):
            super().__init__ (**kwargs)
            self.estimator= Bunch(inv_c = 1)

        def _fit (self, X, y=None):
            self.estimator.inv_c = X.ravel()[0]

        def _apply (self, x):
            return x / self.estimator.inv_c

    class NewPipeline (Pipeline):

        def __init__ (self, **kwargs):
            super().__init__ (**kwargs)

            # custom transform
            self.tr1 = Transform1(**kwargs)

            # slklearn transform
            self.tr2 = PickleSaverComponent(StandardScaler(), **kwargs)

        def _fit (self, X, y=None):
            self.tr1.fit (X)
            self.tr2.fit (X)

    # remove any previously stored
    path_results = 'pipeline_loading_saving'
    remove_previous_results (path_results=path_results)

    pipeline = NewPipeline(path_results=path_results, save_test_result=False)
    pipeline.fit (np.array([3,4,5]).reshape(-1,1))
    result1 = pipeline.transform (np.array([300,400,500]).reshape(-1,1))
    print (pipeline.tr2.estimator.mean_)

    del pipeline
    pipeline = NewPipeline(path_results=path_results, save_test_result=False)
    pipeline.load_estimator ()
    print (pipeline.tr2.estimator.mean_)
    result2 = pipeline.transform (np.array([300,400,500]).reshape(-1,1))

    np.testing.assert_array_equal (result1, result2)

    # remove stored files resulting from running the current test
    remove_previous_results (path_results=path_results)

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails

def build_pipeline_construct_diagram_1 (path_results):
    class Intermediate (MultiComponent):
        def __init__ (self, name=None, **kwargs):
            super().__init__ (name=name, **kwargs)
            self.first = Component (name='first_component', **kwargs)
            self.second = Component (name='second_component', **kwargs)

    class Higher (Pipeline):
        def __init__ (self, **kwargs):
            super().__init__ (**kwargs)
            self.first = Intermediate (name='first_intermediate', class_name='First', **kwargs)
            self.second = Intermediate (name='second_intermediate', class_name='Second', **kwargs)

    pipeline = Higher(path_results=path_results)

    return pipeline

def build_pipeline_construct_diagram_2 (path_results):
    class NewPipeline (Pipeline):
        def __init__ (self, **kwargs):
            data_io = PickleIO (**kwargs)
            super().__init__(data_io=data_io,
                             **kwargs)

            self.tr1 = Component(FunctionTransformer (lambda x: x*3),
                                 data_io=data_io,
                                 class_name='FirstTransform',
                                 name='tr1')
            self.tr2 = Component(FunctionTransformer (lambda x: x*2),
                                 data_io=data_io,
                                 class_name='SecondTransform',
                                 name='tr2')

    pipeline = NewPipeline (path_results=path_results)

    return pipeline

def test_construct_diagram ():
    path_results = 'construct_diagram'
    remove_previous_results (path_results=path_results)

    # ********************************************
    # example without dimensionality of outputs
    # ********************************************
    pipeline = build_pipeline_construct_diagram_1 (path_results)
    diagram = pipeline.construct_diagram ()
    display (diagram)

    # ********************************************
    # example that shows dimensionality of outputs
    # ********************************************
    pipeline = build_pipeline_construct_diagram_2 (path_results)
    X = np.array([1,2,3])
    result = pipeline (X)

    diagram = pipeline.construct_diagram ()
    display (diagram)

    remove_previous_results (path_results=path_results)

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_show_summary ():
    path_results = 'show_summary'
    remove_previous_results (path_results=path_results)

    pipeline = build_pipeline_construct_diagram_2 (path_results)
    X = np.array([1,2,3])
    result = pipeline (X)

    pipeline.show_summary ()

    remove_previous_results (path_results=path_results)

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_make_pipeline ():
    tr1 = Component(FunctionTransformer (lambda x: x+1))
    tr2 = Component(FunctionTransformer (lambda x: x*2))
    pipeline = make_pipeline (tr1, tr2)
    result = pipeline.transform (3)

    print (result)
    assert result == 8

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_pipeline_factory ():
    path_results = 'pipeline_factory'
    remove_previous_results (path_results=path_results)

    pipeline1 = pipeline_factory (SimplePipeline, path_results=path_results)
    assert pipeline1.path_results==Path(path_results).resolve()
    #pipeline2 = pipeline_factory ('SimplePipeline', path_results=path_results)
    #assert pipeline2.path_results==Path(path_results).resolve()

    remove_previous_results (path_results=path_results)

# Comes from compose.ipynb, cell
# **********************************************
# Good example
# **********************************************
class PandasTransformWithLabels1 (PandasComponent):

    def __init__ (self, **kwargs):
        super().__init__ (**kwargs)
        self.estimator= Bunch(sum = 1)

    def _fit (self, X, y=None):
        self.estimator.sum = X[y==1].sum(axis=0)

    def _apply (self, X):
        r = X*1000 + self.estimator.sum
        return r

class PandasTransformWithLabels2 (PandasComponent):

    def __init__ (self, **kwargs):
        super().__init__ (**kwargs)
        self.estimator= Bunch(maxim = 1)

    def _fit (self, X, y=None):
        self.estimator.maxim = X[y==0].max(axis=0)

    def _apply (self, X):
        r = X*100 + self.estimator.maxim
        return r

class SimplePandasPipeline (PandasPipeline):
    def __init__ (self, **kwargs):
        super().__init__ (**kwargs)

        # custom transform
        self.tr1 = PandasTransformWithLabels1(**kwargs)

        # slklearn transform
        self.tr2 = PandasTransformWithLabels2(**kwargs)

# **********************************************
# Bad example
# **********************************************
class TransformWithLabels1 (Component):

    def __init__ (self, **kwargs):
        super().__init__ (**kwargs)
        self.estimator= Bunch(sum = 1)

    def _fit (self, X, y=None):
        self.estimator.sum = X[y==1].sum(axis=0)

    def _apply (self, x):
        return x*1000 + self.estimator.sum

class TransformWithLabels2 (Component):

    def __init__ (self, **kwargs):
        super().__init__ (**kwargs)
        self.estimator= Bunch(maxim = 1)

    def _fit (self, X, y=None):
        self.estimator.maxim = X[y==0].max(axis=0)

    def _apply (self, x):
        return x*100 + self.estimator.maxim


class SimplePandasPipelineNoPandasComponent (PandasPipeline):
    def __init__ (self, **kwargs):
        super().__init__ (**kwargs)

        # custom transform
        self.tr1 = TransformWithLabels1(**kwargs)

        # slklearn transform
        self.tr2 = TransformWithLabels2(**kwargs)


# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_pandas_pipeline ():
    path_results = 'pandas_pipeline'
    remove_previous_results (path_results=path_results)
    df = pd.DataFrame ({'a':[1,2,3,4], 'b': [5,6,7,8], 'label': [1,0,1,0]})

    pipe = SimplePandasPipelineNoPandasComponent ()
    with pytest.raises (KeyError):
        r = pipe.fit_transform (df)
        display (r)

    pipe = SimplePandasPipeline ()
    r = pipe.fit_transform (df)
    display (r)

    tr1 = PandasTransformWithLabels1 ()
    tr2 = PandasTransformWithLabels2 ()
    r1=tr1.fit_transform (df)
    r2=tr2.fit_transform (r1)
    assert (r==r2).all().all()

    df_equal = (r1==df*1000+df[df.label==1].sum(axis=0))[['a','b']]
    assert df_equal.all().all()

    df_equal = (r2==r1*100+r1[r1.label==0].max(axis=0))[['a','b']]
    assert df_equal.all().all()
    remove_previous_results (path_results=path_results)

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_parallel ():
    x = np.array([3,4,5]).reshape(-1,1)
    parallel = Parallel (Transform1 (),
                         Transform2 ())
    r1 = parallel.fit_apply (x)

    x1 = x * 1000 + x.sum(axis=0)
    x2 = x * 100 + x.max(axis=0)
    r_ref = [x1, x2]
    assert all([(x==y).all() for x, y in zip(r1, r_ref)])

    parallel = Parallel (Transform1 (),
                         Transform2 (),
                         initialize_result=lambda : {},
                         join_result=lambda Xr, Xi_r, components, i: {**Xr, **{components[i].name:Xi_r}})

    r1 = parallel.fit_apply (x)
    assert list(r1.keys())==['transform1','transform2']
    assert (r1['transform1']==r_ref[0]).all()
    assert (r1['transform2']==r_ref[1]).all()

# Comes from compose.ipynb, cell
from block_types.utils.dummies import make_pipe1, make_pipe2
def test_pipeline_find_last_result ():
    path_results = 'test_pipeline_find_last_result'

    # pipelines
    pipe1 = make_pipe1 ()
    X = np.array([1,2,3]).reshape(-1,1)
    r1 = pipe1.apply (X)
    print (r1)
    pipe2 = make_pipe1 (path_results=path_results, verbose=2)
    a, b = pipe2.A, pipe2.B
    # second
    X2 = a.apply (X)
    X2 = b.apply (X2)

    is_source = pipe2.find_last_result ()
    assert is_source

    pipe2.A.raise_error = True
    pipe2.B.raise_error = False
    pipe2.C.raise_error = False
    pipe2.D.raise_error = False
    pipe2.E.raise_error = False
    with pytest.raises (RuntimeError):
        _ = a.apply (X)
    pipe2.C.raise_error = True
    with pytest.raises (RuntimeError):
        _ = pipe2.apply ()
    pipe2.C.raise_error = False
    r2 = pipe2.apply ()
    assert (r1==r2).all()
    print (r2)

    remove_previous_results (path_results=path_results)

def test_pipeline_find_last_result_parallel1 ():
    path_results = 'test_pipeline_find_last_result_parallel1'

    remove_previous_results (path_results=path_results)
    # pipelines
    pipe1 = make_pipe2 ()
    X = np.array([1,2,3]).reshape(1,-1)
    r1 = pipe1.apply (X)
    print (r1)
    # second
    pipe2 = make_pipe2 (path_results=path_results, verbose=2, root=True)
    a = pipe2.obj.A (X)
    b1 = pipe2.obj.B1 (a)
    b2a = pipe2.obj.B2a (a)
    b3a = pipe2.obj.B3a (a)
    b3b = pipe2.obj.B3b (b3a)

    #pipe2.obj.A.raise_error = True
    #pipe2.obj.B1.raise_error = True
    #pipe2.obj.B2a.raise_error = True
    pipe2.obj.B3a.raise_error = True
    #pipe2.obj.B3b.raise_error = True

    is_source = pipe2.find_last_result ()
    print (is_source)
    r2 = pipe2.apply ()
    assert (r1==r2).all()
    print (r2)

    remove_previous_results (path_results=path_results)

def test_pipeline_find_last_result_parallel2 ():
    path_results = 'test_pipeline_find_last_result_parallel2'

    remove_previous_results (path_results=path_results)
    # pipelines
    pipe1 = make_pipe2 ()
    X = np.array([1,2,3]).reshape(1,-1)
    r1 = pipe1.apply (X)
    print (r1)
    # second
    pipe2 = make_pipe2 (path_results=path_results, verbose=2, root=True)
    a = pipe2.obj.A (X)
    # B1
    b1 = pipe2.obj.B1 (a)
    # B2
    b2a = pipe2.obj.B2a (a)
    b2b = pipe2.obj.B2b (b2a)
    b2c = pipe2.obj.B2c (b2b)
    # B3
    b3a = pipe2.obj.B3a (a)
    b3b = pipe2.obj.B3b (b3a)
    b3c = pipe2.obj.B3c (b3b)
    # B4
    b4 = pipe2.obj.B4 (a)

    pipe2.obj.A.raise_error = True
    pipe2.obj.B2a.raise_error = True
    pipe2.obj.B2b.raise_error = True

    pipe2.obj.B3a.raise_error = True
    pipe2.obj.B3b.raise_error = True

    is_source = pipe2.find_last_result ()
    print (is_source)
    r2 = pipe2.apply ()
    assert (r1==r2).all()

    remove_previous_results (path_results=path_results)

def test_pipeline_find_last_result_parallel3 ():
    global pipe2
    path_results = 'test_pipeline_find_last_result_parallel3'

    remove_previous_results (path_results=path_results)
    # pipelines
    pipe1 = make_pipe2 ()
    X = np.array([1,2,3]).reshape(1,-1)
    r1 = pipe1.apply (X)
    print (r1)
    # second
    pipe2 = make_pipe2 (path_results=path_results, verbose=2, root=True, new_parallel=True)
    a = pipe2.obj.A (X)
    # B
    b = pipe2.new_parallel (a)
    # B2
    c = pipe2.obj.C (b)

    pipe2.obj.A.raise_error = True
    pipe2.new_parallel.raise_error = True

    is_source = pipe2.find_last_result ()
    print (is_source)
    r2 = pipe2.apply ()
    assert (r1==r2).all()

    remove_previous_results (path_results=path_results)

# Comes from compose.ipynb, cell
from block_types.utils.dummies import make_pipe_fit1

def test_pipeline_find_last_fitted_model_seq ():
    path_results = 'test_pipeline_find_last_fitted_model_seq'
    remove_previous_results (path_results=path_results)

    # pipelines
    pipe1 = make_pipe_fit1 ()
    X = np.array([1,2,3]).reshape(-1,1)
    r1 = pipe1.fit_apply (X)
    print (r1)
    pipe2 = make_pipe_fit1 (path_results=path_results, verbose=2)
    # second
    r = pipe2.A.fit_apply (X)
    r = pipe2.B.fit_apply (r)
    r = pipe2.C.fit_apply (r)
    r = pipe2.D.fit_apply (r)

    all_fitted = pipe2.find_last_fitted_model ()
    assert not all_fitted

    pipe2.A.raise_error = True
    pipe2.B.raise_error = True
    pipe2.B.create_estimator()
    assert pipe2.B.estimator == Bunch()
    pipe2.C.raise_error = True
    pipe2.C.create_estimator()
    assert pipe2.C.estimator == Bunch()
    r2 = pipe2.fit_apply (None)
    assert (r1==r2).all()
    print (r2)

    remove_previous_results (path_results=path_results)

# Comes from compose.ipynb, cell
from block_types.utils.dummies import make_pipe_fit2

def test_pipeline_find_last_fitted_model_parallel ():
    path_results = 'test_pipeline_find_last_fitted_model_parallel'
    remove_previous_results (path_results=path_results)

    # pipelines
    pipe1 = make_pipe_fit2 ()
    X = np.array([1,2,3]).reshape(-1,1)
    r1 = pipe1.fit_apply (X)
    print (r1)
    pipe2 = make_pipe_fit2 (path_results=path_results, verbose=2, root=True)
    # second
    r = pipe2.A0.fit_apply (X)
    r = pipe2.A1.fit_apply (r)
    b2 = pipe2.obj.B2.fit_apply (r)
    b3a = pipe2.obj.B3a.fit_apply (r)
    b3b = pipe2.obj.B3b.fit_apply (b3a)
    b4a = pipe2.obj.B4a.fit_apply (r)
    b4b = pipe2.obj.B4b.fit_apply (b4a)
    b4c = pipe2.obj.B4c.fit_apply (b4b)
    b4d = pipe2.obj.B4d.fit_apply (b4c)
    b4e = pipe2.obj.B4e.fit_apply (b4d)

    all_fitted = pipe2.find_last_fitted_model ()
    assert not all_fitted

    pipe2.A0.raise_error = True
    pipe2.obj.B3a.raise_error = True
    pipe2.obj.B4a.raise_error = True
    pipe2.obj.B4b.raise_error = True
    pipe2.obj.B4c.raise_error = True
    pipe2.obj.B4d.raise_error = True

    pipe2.A1.create_estimator()
    pipe2.obj.B2.create_estimator()
    pipe2.obj.B3a.create_estimator()
    pipe2.obj.B3b.create_estimator()
    pipe2.obj.B4b.create_estimator()
    pipe2.obj.B4c.create_estimator()
    pipe2.obj.B4e.create_estimator()

    pipe2.logger.info (f'\n{"-"*100}\n')
    r2 = pipe2.fit_apply (None)
    assert (r1==r2).all()

    remove_previous_results (path_results=path_results)

def test_pipeline_find_last_fitted_model_parallel_remove ():

    path_results = 'test_pipeline_find_last_fitted_model_parallel_remove'
    remove_previous_results (path_results=path_results)

    # ******************************************************
    # pipelines
    pipe1 = make_pipe_fit2 ()
    X = np.array([1,2,3]).reshape(-1,1)
    r1 = pipe1.fit_apply (X)

    # ******************************************************
    pipe2 = make_pipe_fit2 (path_results=path_results, verbose=2, root=True)

    r = pipe2.A0.fit_apply (X)
    r = pipe2.A1.fit_apply (r)

    b1 = pipe2.obj.B1.fit_apply (r)
    b2 = pipe2.obj.B2.fit_apply (r)

    b3a = pipe2.obj.B3a.fit_apply (r)
    b3b = pipe2.obj.B3b.fit_apply (b3a)
    b3c = pipe2.obj.B3c.fit_apply (b3b)
    b3d = pipe2.obj.B3d.fit_apply (b3c)

    b4a = pipe2.obj.B4a.fit_apply (r)
    b4b = pipe2.obj.B4b.fit_apply (b4a)
    b4c = pipe2.obj.B4c.fit_apply (b4b)
    b4d = pipe2.obj.B4d.fit_apply (b4c)
    b4e = pipe2.obj.B4e.fit_apply (b4d)

    b5 = pipe2.obj.B5.fit_apply (r)

    pipe2.obj.B4d.set_load_result (False)
    pipe2.obj.B4e.set_load_result (False)

    all_fitted = pipe2.find_last_fitted_model ()
    assert not all_fitted

    pipe2.A0.raise_error = True
    pipe2.A1.raise_error = True

    pipe2.obj.B1.applied = False
    pipe2.obj.B2.fit_applied = False

    pipe2.obj.B3a.raise_error = True
    pipe2.obj.B3b.raise_error = True
    pipe2.obj.B3c.raise_error = True
    pipe2.obj.B3d.fit_applied = False

    pipe2.obj.B4a.raise_error = True
    pipe2.obj.B4b.raise_error = True
    pipe2.obj.B4c.fit_applied = False
    pipe2.obj.B4d.applied = False
    pipe2.obj.B4e.fit_applied = False

    pipe2.obj.B5.fit_applied = False

    pipe2.A1.create_estimator()
    pipe2.obj.B2.create_estimator()
    pipe2.obj.B3a.create_estimator()
    pipe2.obj.B3b.create_estimator()
    pipe2.obj.B4b.create_estimator()
    pipe2.obj.B4c.create_estimator()
    pipe2.obj.B4e.create_estimator()
    pipe2.obj.B5.create_estimator()

    pipe2.logger.info (f'\n{"-"*100}\n')
    r2 = pipe2.fit_apply (None)
    assert (r1==r2).all()

    assert pipe2.obj.B1.applied
    assert pipe2.obj.B2.fit_applied
    assert pipe2.obj.B3d.fit_applied

    assert pipe2.obj.B4c.fit_applied
    assert pipe2.obj.B4d.applied
    assert pipe2.obj.B4e.fit_applied

    assert pipe2.obj.B5.fit_applied

    remove_previous_results (path_results=path_results)

    # ******************************************************
    pipe2.logger.info (f'\n{"*"*100}\n{"*"*100}\n')
    pipe2 = make_pipe_fit2 (path_results=path_results, verbose=2, root=True)
    # second
    r = pipe2.A0.fit_apply (X)
    r = pipe2.A1.fit_apply (r)

    b1 = pipe2.obj.B1.fit_apply (r)
    b2 = pipe2.obj.B2.fit_apply (r)

    b3a = pipe2.obj.B3a.fit_apply (r)
    b3b = pipe2.obj.B3b.fit_apply (b3a)
    b3c = pipe2.obj.B3c.fit_apply (b3b)
    b3d = pipe2.obj.B3d.fit_apply (b3c)

    b4a = pipe2.obj.B4a.fit_apply (r)
    b4b = pipe2.obj.B4b.fit_apply (b4a)
    b4c = pipe2.obj.B4c.fit_apply (b4b)
    b4d = pipe2.obj.B4d.fit_apply (b4c)
    b4e = pipe2.obj.B4e.fit_apply (b4d)

    b5 = pipe2.obj.B5.fit_apply (r)

    os.remove (pipe2.obj.B4d.data_io.get_path_result_file ())
    os.remove (pipe2.obj.B4e.data_io.get_path_result_file ())


    all_fitted = pipe2.find_last_fitted_model ()
    assert not all_fitted

    pipe2.A0.raise_error = True
    pipe2.A1.raise_error = True

    pipe2.obj.B1.applied = False
    pipe2.obj.B2.fit_applied = False

    pipe2.obj.B3a.raise_error = True
    pipe2.obj.B3b.raise_error = True
    pipe2.obj.B3c.raise_error = True
    pipe2.obj.B3d.fit_applied = False

    pipe2.obj.B4a.raise_error = True
    pipe2.obj.B4b.raise_error = True
    pipe2.obj.B4c.fit_applied = False
    pipe2.obj.B4d.applied = False
    pipe2.obj.B4e.fit_applied = False

    pipe2.obj.B5.fit_applied = False

    pipe2.A1.create_estimator()
    pipe2.obj.B2.create_estimator()
    pipe2.obj.B3a.create_estimator()
    pipe2.obj.B3b.create_estimator()
    pipe2.obj.B4b.create_estimator()
    pipe2.obj.B4c.create_estimator()
    pipe2.obj.B4e.create_estimator()
    pipe2.obj.B5.create_estimator()

    pipe2.logger.info (f'\n{"-"*100}\n')
    r2 = pipe2.fit_apply (None)
    assert (r1==r2).all()

    assert pipe2.obj.B1.applied
    assert pipe2.obj.B2.fit_applied
    assert pipe2.obj.B3d.fit_applied

    assert pipe2.obj.B4c.fit_applied
    assert pipe2.obj.B4d.applied
    assert pipe2.obj.B4e.fit_applied

    assert pipe2.obj.B5.fit_applied


    remove_previous_results (path_results=path_results)

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
class TransformM (Component):

    def __init__ (self, modality='', factor=1000, **kwargs):
        super().__init__ (**kwargs)
        self.estimator= Bunch(sum = 1)

    def _fit (self, X, y=None):
        self.estimator.sum = X.sum(axis=0)

    def _apply (self, x):
        return x*self.factor + self.estimator.sum

def test_multi_modality ():
    data = {'transform1': np.array([1,2,3]),
            'transform2': np.array([10,20,30])}

    parallel = MultiModality (Transform1 (),
                              Transform2 (),
                              use_name=True)
    r = parallel.fit_apply (data)

    x1 = data['transform1']
    x1 = x1 * 1000 + x1.sum(axis=0)
    x2 = data['transform2']
    x2 = x2 * 100 + x2.max(axis=0)
    assert list(r.keys())==['transform1','transform2']
    assert (r['transform1']==x1).all()
    assert (r['transform2']==x2).all()

    # with configs
    data = dict(modA=np.array([1,2,3]),
                modB=np.array([10,20,30]))
    configs = dict(modA=dict (modality='A', factor=2000),
                   modB=dict (modality='B', factor=3000))

    parallel = MultiModality (component_class=TransformM,
                              configs=configs)
    r = parallel.fit_apply (data)

    x1 = data['modA']
    x1 = x1 * 2000 + x1.sum(axis=0)
    x2 = data['modB']
    x2 = x2 * 3000 + x2.sum(axis=0)
    assert list(r.keys())==['modA','modB']
    assert (r['modA']==x1).all()
    assert (r['modB']==x2).all()

    assert parallel.transform_m_modA.modality == 'A'
    assert parallel.transform_m_modB.modality == 'B'

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_column_selector ():
    df = pd.DataFrame ({'x1': list(range(5)),
                    'x2': list(range(5,10)),
                    'x3': list(range(15,20)),
                    'x4': list(range(25,30))
                   })
    dfr = ColumnSelector(columns=['x2','x4'], error_if_apply=True).transform(df)
    assert (dfr==df[['x2','x4']]).all().all()

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_concat ():
    df = pd.DataFrame ({'x1': list(range(5)),
                    'x2': list(range(5,10)),
                    'x3': list(range(15,20)),
                    'x4': list(range(25,30))
                   })

    df2 = pd.DataFrame ({'x5': list(range(5)),
                    'x6': list(range(5,10)),
                    'x7': list(range(15,20))
                   })
    dfr = Concat (error_if_apply=True).transform(df, df2)
    assert (dfr==pd.concat ([df,df2], axis=1)).all().all()

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_identity ():
    df = pd.DataFrame ({'x1': list(range(5)),
                    'x2': list(range(5,10)),
                    'x3': list(range(15,20)),
                    'x4': list(range(25,30))
                   })

    dfr = Identity (error_if_apply=True).transform(df)
    assert (dfr==df).all().all()

# Comes from compose.ipynb, cell
def column_transformer_data ():
    df = pd.DataFrame ({'cont1': list(range(5)),
                        'cont2': list(range(5,10)),
                        'cont3': list(range(15,20)),
                        'cont4': list(range(25,30)),
                        'cat_1': list([1,2,3,2,1]),
                        'cat_2': list([0,1,1,0,0])
                        })

    tr1 = Component(FunctionTransformer (lambda x: x+1), name='tr1')

    return df, tr1

#@pytest.mark.reference_fails
def test_make_column_transformer (column_transformer_data):

    df, tr1 = column_transformer_data

    tr1 = Component(FunctionTransformer (lambda x: x+1), name='tr1')
    tr2 = PandasComponent(FunctionTransformer (lambda x: x*2),
                          transformed_columns=['cont2_bis','cat_1'],
                          name='tr2')

    column_transformer = make_column_transformer (
        (tr1, ['cont2', 'cont4']),
        (tr2, ['cont2', 'cat_1']),
        error_if_apply=True,
        verbose=2
    )
    print (f'{"-"*100}\n{column_transformer}')
    dfr = column_transformer.transform(df)

    # display and test
    display(dfr)
    assert (dfr[['cont2','cont4']] == tr1(df[['cont2','cont4']])).all().all()
    assert (dfr[['cont2_bis','cat_1']] == tr2(df[['cont2','cat_1']])).all().all()
    assert (dfr.columns == ['cont2','cont4', 'cont2_bis','cat_1']).all()
    assert (column_transformer.name, column_transformer.class_name) == ('__base_column_transformer', '_BaseColumnTransformer')

    # set name of column transformer
    column_transformer = make_column_transformer (
        (tr1, ['cont2', 'cont4']),
        (tr2, ['cont2', 'cat_1']),
        name='test_transformer',
        class_name='TestTransformer',
        error_if_apply=True,
        verbose=2
    )
    print (f'{"-"*100}\n{column_transformer}')
    assert (column_transformer.name, column_transformer.class_name) == ('test_transformer', 'TestTransformer')

    # set name of column transformer and parameters that are specific
    # for the column_transformer: path_results
    column_transformer = make_column_transformer (
        (tr1, ['cont2', 'cont4']),
        (tr2, ['cont2', 'cat_1']),
        name='test_transformer',
        class_name='TestTransformer',
        TestTransformer=dict(path_results='mine'),
        path_results='other',
        error_if_apply=True,
        verbose=2
    )
    print (f'{"-"*100}\n{column_transformer}')
    assert column_transformer.path_results.name=='mine'
    assert column_transformer.components[0].path_results.name=='other'

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_make_column_transformer_passthrough (column_transformer_data):
    df, tr1 = column_transformer_data

    column_transformer = make_column_transformer (
        (tr1, ['cont1', 'cont4']),
        ('passthrough', ['cont2', 'cat_1']),
        error_if_apply=True,
        verbose=2
    )
    dfr = column_transformer.transform(df)

    # display and test
    display(dfr)
    assert (dfr[['cont1','cont4']] == tr1(df[['cont1','cont4']])).all().all()
    assert (dfr[['cont2','cat_1']] == df[['cont2','cat_1']]).all().all()
    assert (dfr.columns == ['cont1','cont4', 'cont2','cat_1']).all()

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_make_column_transformer_remainder (column_transformer_data):

    df, tr1 = column_transformer_data

    # remainder is new transformation
    tr3 = Component(FunctionTransformer (lambda x: x+100), name='tr3')
    column_transformer = make_column_transformer (
        (tr1, ['cont1', 'cont4']),
        ('passthrough', ['cont2', 'cat_1']),
        remainder=tr3,
        error_if_apply=True,
        verbose=2
    )
    dfr = column_transformer.transform(df)

    # display and test
    display('with tr3', dfr)
    assert (dfr[['cont1','cont4']] == tr1(df[['cont1','cont4']])).all().all()
    assert (dfr[['cont2','cat_1']] == df[['cont2','cat_1']]).all().all()
    assert (dfr[['cont3','cat_2']] == tr3(df[['cont3','cat_2']])).all().all()
    assert (dfr.columns == ['cont1','cont4', 'cont2','cat_1','cont3','cat_2']).all()

    # remainder is passthrough
    del tr1.nick_name
    del tr3.nick_name
    column_transformer = make_column_transformer (
        (tr1, ['cont1', 'cont4']),
        (tr3, ['cont2', 'cat_1']),
        remainder='passthrough',
        error_if_apply=True,
        verbose=2
    )
    dfr = column_transformer.transform(df)

    display('with passthrough', dfr)
    assert (dfr[['cont1','cont4']] == tr1(df[['cont1','cont4']])).all().all()
    assert (dfr[['cont2','cat_1']] == tr3(df[['cont2','cat_1']])).all().all()
    assert (dfr[['cont3','cat_2']] == df[['cont3','cat_2']]).all().all()
    assert (dfr.columns == ['cont1','cont4', 'cont2','cat_1','cont3','cat_2']).all()

    # remainder is tr3, and one of the transforms is drop
    del tr1.nick_name
    del tr3.nick_name
    column_transformer = make_column_transformer (
        (tr1, ['cont1', 'cont4']),
        ('drop', ['cont2', 'cat_1']),
        remainder=tr3,
        error_if_apply=True,
        verbose=2
    )
    dfr = column_transformer.transform(df)

    display('with drop one of the transforms - cont2, cat_1', dfr)
    assert (dfr[['cont1','cont4']] == tr1(df[['cont1','cont4']])).all().all()
    assert (dfr[['cont3','cat_2']] == tr3(df[['cont3','cat_2']])).all().all()
    assert (dfr.columns == ['cont1','cont4', 'cont3','cat_2']).all()

    # check gather_descendants
    column_transformer.gather_descendants()
    assert sorted(column_transformer.full_obj.keys())==['column_selector', 'concat', 'tr1', 'tr1_cc', 'tr3', 'tr3_rem']

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_make_column_transformer_descendants (column_transformer_data):

    df, tr1 = column_transformer_data

    tr3 = Component(FunctionTransformer (lambda x: x+100), name='tr3')

    column_transformer = make_column_transformer (
        (tr1, ['cont1', 'cont4']),
        ('drop', ['cont2', 'cat_1']),
        remainder=tr3
    )

    # check gather_descendants
    column_transformer.gather_descendants()
    assert sorted(column_transformer.full_obj.keys())==['column_selector', 'concat', 'tr1', 'tr1_cc', 'tr3', 'tr3_rem']

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_make_column_transformer_fit_transform (column_transformer_data):

    df, tr1 = column_transformer_data

    class SumTimes100 (Component):
        def _fit (self, X, y=None):
            self.sum = X.sum(axis=0)
        def _apply (self, X):

            dfr = pd.DataFrame ({'c1_times100': self.sum.values[0]*100 + X.iloc[:,0].values,
                                 'c2_times100': self.sum.values[1]*100 + X.iloc[:,1].values,
                                 'c2_times1000': self.sum.values[1]*1000 + X.iloc[:,1].values})
            return dfr

    tr1 = SumTimes100 ()
    tr2 = PandasComponent(FunctionTransformer (lambda x: x*2), name='tr2')

    column_transformer = make_column_transformer (
        (tr1, ['cont2', 'cont4']),
        (tr2, ['cont2', 'cat_1']),
        error_if_apply=True,
        verbose=2
    )
    dfr = column_transformer.fit_transform(df)

    # display & test
    display(dfr)
    assert (dfr.columns == ['c1_times100','c2_times100', 'c2_times1000','cont2', 'cat_1']).all()
    assert (dfr['c1_times100'] == sum(df.cont2)*100+df.cont2).all()
    assert (dfr['c2_times100'] == sum(df.cont4)*100+df.cont4).all()
    assert (dfr['c2_times1000'] == sum(df.cont4)*1000+df.cont4).all()

# Comes from compose.ipynb, cell
class Transform1 (Component):
    def __init__ (self, **kwargs):
        super().__init__ (**kwargs)
        self.estimator= Bunch(sum = 1)

    def _fit (self, X, y=None):
        self.estimator.sum = X.sum(axis=0)

    def _apply (self, x):
        return x*1000 + self.estimator.sum

class Transform2 (Component):
    def __init__ (self, **kwargs):
        super().__init__ (**kwargs)
        self.estimator= Bunch(maxim = 1)

    def _fit (self, X, y=None, validation_data=None, test_data=None):
        self.estimator.maxim = X.max(axis=0)

        print (f'validation_data: {validation_data}')
        print (f'test_data: {test_data}')

        self.data = dict (validation=validation_data,
                          test=test_data)

    def _apply (self, x):
        return x*100 + self.estimator.maxim

def multi_split_data ():
    data = dict(training = np.array([1,2,3]).reshape(-1,1),
            validation = np.array([10,20,30]).reshape(-1,1),
            test = np.array([100,200,300]).reshape(-1,1)
            )

    multi_transform1 = MultiSplitDict (component = Transform1())

    tr2 = Transform2()
    multi_transform2 = MultiSplitDict (component=tr2,
                                            fit_additional = ['validation', 'test'])

    return data, multi_transform1, multi_transform2, tr2

#@pytest.mark.reference_fails
def test_multi_split_transform (multi_split_data):
    # example 1: apply transform on multiple splits
    data, multi_transform1, multi_transform2, tr2 = multi_split_data

    result = multi_transform1.fit_transform (data)

    assert type(result) is dict
    assert result.keys() == data.keys()
    for split in result.keys():
        assert (result[split]==sum(data['training'].ravel())+data[split]*1000).all()

    # check that automatic name given is based on component
    assert multi_transform1.name=='transform1_multi_split'
    assert multi_transform1.class_name=='Transform1MultiSplit'

    # check that we can assign a different name
    multi_transform1 = MultiSplitDict (component = Transform1(), name='different', class_name='Yes')
    assert multi_transform1.name=='different'
    assert multi_transform1.class_name=='Yes'
    # check that this new name is given only to MultiSplitDict,
    # not to the component that it's wrapping
    assert multi_transform1.component.name=='transform1'
    assert multi_transform1.component.class_name=='Transform1'

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_multi_split_fit (multi_split_data):
    # example 2: fit method gets training, validation and test
    data, multi_transform1, multi_transform2, tr2 = multi_split_data
    # we apply the transform to only test


    # we apply the transform to only test data
    result = multi_transform2.fit_transform (data, apply_to='test')

    assert type(result) is dict
    assert list(result.keys()) == ['test']
    for split in result.keys():
        assert (result[split]==max(data['training'].ravel())+data[split]*100).all()

    for split in ['validation', 'test']:
        assert (tr2.data[split] == data[split]).all()

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_multi_split_chain (multi_split_data):
    data, multi_transform1, multi_transform2, tr2 = multi_split_data

    # test that we can chain transformations

    result = multi_transform1.fit_transform (data)
    result = multi_transform2.fit_transform (result, apply_to='test')

    import pytest

    #check that we have no error if split does not exist
    result = multi_transform1.fit_transform (data, apply_to=['training', 'validation'])
    result = multi_transform2.fit_transform (result, apply_to=['test'])
    assert len(result)==0

    #check that we have an error if we set the flag `raise_error_if_split_doesnot_exist=True`
    multi_transform2.raise_error_if_split_doesnot_exist = True
    result = multi_transform1.fit_transform (data, apply_to=['training', 'validation'])
    with pytest.raises (RuntimeError):
        result = multi_transform2.fit_transform (result, apply_to=['test'])

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_multi_split_io (multi_split_data):

    data, multi_transform1, multi_transform2, tr2 = multi_split_data

    # check loading / saving
    from block_types.utils.utils import remove_previous_results
    from block_types.core.utils import PickleIO

    path_results = 'results_multi_split'

    remove_previous_results (path_results=path_results)

    tr = PickleSaverComponent (FunctionTransformer (lambda x: x*2),
                    name='times2',
                    path_results=path_results)

    multi_transform = MultiSplitDict (component=tr,
                                           apply_to = ['validation', 'test'],
                                           path_results = path_results,
                                           data_io=PickleIO (path_results = path_results))

    result = multi_transform (data)

    multi_transform2 = MultiSplitDict (data_io=PickleIO (path_results = path_results), name='times2_multi_split')

    result2 = multi_transform2.data_io.load_result ()

    for k in result.keys():
        assert (result[k] == result2[k]).all()

    assert result.keys()==result2.keys()

    assert sorted(os.listdir(path_results))==['test', 'validation', 'whole']

    assert (tr.data_io.load_result(split='test') == result['test']).all()

    assert (tr.data_io.load_result(split='validation') == result['validation']).all()

    assert os.listdir(f'{path_results}/validation')==['times2_result.pk']

    assert os.listdir(f'{path_results}/test')==['times2_result.pk']

    assert os.listdir(f'{path_results}/whole')==['times2_multi_split_result.pk']

    remove_previous_results (path_results=path_results)

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_multi_split_non_dict ():
    # check loading / saving
    tr = Component (FunctionTransformer (lambda x: x*2))

    multi_transform = MultiSplitDict (tr, apply_to = ['test'])

    data = np.array([100,200,300]).reshape(-1,1)
    result = multi_transform (data)

    assert type(result)==np.ndarray
    assert (result==data*2).all()

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_multi_split_non_dict_bis ():
    tr = Component (FunctionTransformer (lambda x: x*2))

    multi_transform = MultiSplitDict (tr, apply_to = ['test'])

    # output applied to single split, converted to non-dictionary
    data = dict(training = np.array([1,2,3]).reshape(-1,1),
                validation = np.array([10,20,30]).reshape(-1,1),
                test = np.array([100,200,300]).reshape(-1,1))
    result = multi_transform (data, output_not_dict=True)

    assert type(result)==np.ndarray
    assert (result==data['test']*2).all()

# Comes from compose.ipynb, cell
def multi_split_data_df_column ():
    data = dict(training = np.array([1,2,3]).reshape(-1,1),
            validation = np.array([10,20,30]).reshape(-1,1),
            test = np.array([100,200,300]).reshape(-1,1)
            )

    values = np.concatenate((data['training'], data['validation'], data['test']))
    df = pd.DataFrame (data=values)
    split = [[k]*data[k].shape[0] for k in data]
    df['split'] = split[0] + split[1] + split[2]

    multi_transform1 = MultiSplitDFColumn (component = Transform1())

    tr2 = Transform2()
    multi_transform2 = MultiSplitDFColumn (component=tr2,
                                            fit_additional = ['validation', 'test'])

    return df, data, multi_transform1, multi_transform2, tr2

def test_multi_split_df_column_transform ():
    # example 1: apply transform on multiple splits
    df, data, multi_transform1, multi_transform2, tr2 = multi_split_data_df_column ()

    result = multi_transform1.fit_transform (df)

    assert type(result) is pd.DataFrame

    assert (result.split.unique() == list(data.keys())).all()

    for split in data.keys():
        assert (result[result.split==split].drop(columns='split').values==sum(data['training'].ravel())+data[split]*1000).all()

    # check that automatic name given is based on component
    assert multi_transform1.name=='transform1_multi_split'
    assert multi_transform1.class_name=='Transform1MultiSplit'

    # check that we can assign a different name
    multi_transform1 = MultiSplitDict (component = Transform1(), name='different', class_name='Yes')
    assert multi_transform1.name=='different'
    assert multi_transform1.class_name=='Yes'
    # check that this new name is given only to MultiSplitDict,
    # not to the component that it's wrapping
    assert multi_transform1.component.name=='transform1'
    assert multi_transform1.component.class_name=='Transform1'

# Comes from compose.ipynb, cell
#@pytest.mark.reference_fails
def test_multi_split_df_column_fit ():
    """Example 2: fit method gets training, validation and test."""
    df, data, multi_transform1, multi_transform2, tr2 = multi_split_data_df_column ()
    # we apply the transform to only test


    # we apply the transform to only test data
    result = multi_transform2.fit_transform (df, apply_to='test')

    assert type(result) is pd.DataFrame
    assert list(result.split.unique()) == ['test']

    for split in result.split.unique():
        assert (result[result.split==split].drop(columns='split').values==max(data['training'].ravel())+data[split]*100).all()

    for split in ['validation', 'test']:
        assert (tr2.data[split] == df[df.split==split]).all().all()