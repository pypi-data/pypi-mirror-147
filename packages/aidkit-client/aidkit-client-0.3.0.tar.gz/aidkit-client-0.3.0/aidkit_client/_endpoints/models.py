# generated by datamodel-codegen:
#   filename:  <stdin>

from __future__ import annotations

from enum import Enum
from typing import Any, Dict, List, Optional, Union

from pydantic import BaseModel, Field
from typing_extensions import Literal


class MLModelVersionResponse(BaseModel):
    """
    MLModel version response model.
    """

    id: int = Field(..., title="Id")
    name: str = Field(..., title="Name")
    pipeline_run_ids: List[int] = Field(..., title="Pipeline Run Ids")


class ListMLModelVersionResponse(BaseModel):
    """
    List MLModel version response model.
    """

    ml_model_versions: List[MLModelVersionResponse] = Field(..., title="Ml Model Versions")


class FrameworkType(Enum):
    """
    Identification of the type of deep learning framework.

    Required for parsing model binaries with the correct libraries.
    """

    TENSORFLOW = "TENSORFLOW"
    PYTORCH = "PYTORCH"


class BatchDim(Enum):
    """
    Location of batch dimension, if it exists.
    """

    First = "First"
    Last = "Last"
    No_Batch = "No Batch"


class SpecificLengthDimensionModel(BaseModel):
    """
    Output dimension length has to be specified.
    """

    axis: int = Field(..., title="Axis")
    length: int = Field(..., description="Length of dimension.", gt=0.0, title="Length")


class GrayScaleChannelDimensionModel(BaseModel):
    """
    Gray scale channel dimension must be of length 1.
    """

    axis: int = Field(..., title="Axis")
    length: Literal[1] = Field(1, title="Length")


class UnspecifiedLengthDimensionModel(BaseModel):
    """
    Output dimension can be of any length.
    """

    axis: int = Field(..., title="Axis")
    length: Literal["*"] = Field("*", title="Length")


class GrayScaleImageInputDimensionsModel(BaseModel):
    """
    Gray Scale Image input has optional batch dimension.
    """

    height: SpecificLengthDimensionModel = Field(
        ..., description="Height axis index and length", title="Height axis"
    )
    width: SpecificLengthDimensionModel = Field(
        ..., description="Width axis index and length", title="Width axis"
    )
    channel: GrayScaleChannelDimensionModel = Field(
        ..., description="Channel axis index", title="Channel axis"
    )
    batch: Optional[UnspecifiedLengthDimensionModel] = Field(
        None, description="Batch axis and length", title="Batch axis"
    )


class InputRangeTypes(Enum):
    """
    Range of pixel values.
    """

    MinusOneOne = "MinusOneOne"
    ZeroOne = "ZeroOne"


class Normalizer(BaseModel):
    """
    Normalize data to a given range.
    """

    input_range: InputRangeTypes = Field("ZeroOne", title="Expected Input Range")


class Standardizer(BaseModel):
    """
    Standardize the data with a given mean and standard deviation.
    """

    data_mean: float = Field(0.0, title="Mean")
    data_std: float = Field(1.0, gt=0.0, title="Standard Deviation")


class GrayScaleImageInputSpecs(BaseModel):
    """
    A grayscale image has 1 channel.
    """

    name: Literal["GrayScaleImage"] = Field("GrayScaleImage", title="Image (Grayscale)")
    batch_dim: BatchDim = Field("No Batch", title="Batch Axis Location")
    dimensions: GrayScaleImageInputDimensionsModel
    pre_processor: Union[Normalizer, Standardizer] = Field(
        {"input_range": "ZeroOne"},
        description=(
            "Can choose between normalizing data to a range or standardizing data to given mean and"
            " standard deviation."
        ),
        title="Pre Processor",
    )


class ColorChannelDimensionModel(BaseModel):
    """
    Color channel dimension must be of length 3.
    """

    axis: int = Field(..., title="Axis")
    length: Literal[3] = Field(3, title="Length")


class ColorImageInputDimensionsModel(BaseModel):
    """
    Color Image input has optional batch dimension.
    """

    height: SpecificLengthDimensionModel = Field(
        ..., description="Height axis index and length", title="Height axis"
    )
    width: SpecificLengthDimensionModel = Field(
        ..., description="Width axis index and length", title="Width axis"
    )
    channel: ColorChannelDimensionModel = Field(
        ..., description="Channel axis index", title="Channel axis"
    )
    batch: Optional[UnspecifiedLengthDimensionModel] = Field(
        None, description="Batch axis and length", title="Batch axis"
    )


class ColorImageInputSpecs(BaseModel):
    """
    A color image has 3 channels.
    """

    name: Literal["ColorImage"] = Field("ColorImage", title="Image (Color)")
    batch_dim: BatchDim = Field("No Batch", title="Batch Axis Location")
    dimensions: ColorImageInputDimensionsModel
    pre_processor: Union[Normalizer, Standardizer] = Field(
        {"input_range": "ZeroOne"},
        description=(
            "Can choose between normalizing data to a range or standardizing data to given mean and"
            " standard deviation."
        ),
        title="Pre Processor",
    )


class AutogeneratedClasses(BaseModel):
    """
    The class names are auto-generated, e.g., class_01, class_02, ..., class_10
    for a total of 10 classes.
    """

    num_classes: int = Field(
        ..., description="Specify the total number of classes. ", gt=0.0, title="Number of Classes "
    )


class DictOutputFormat(BaseModel):
    """
    Model outputs a dictionary of tensors.
    """

    name: Literal["Dict"] = Field("Dict", title="Dictionary of Tensors")
    output_target: str = Field(..., title="Output Target")


class SingleOutputFormat(BaseModel):
    """
    Model outputs a single tensor.
    """

    name: Literal["Single"] = Field("Single", title="Single Tensor")


class ClassificationScoreDimensionsModel(BaseModel):
    """
    Classification Output has class dimension.
    """

    class_: Optional[UnspecifiedLengthDimensionModel] = Field(None, title="Class axis")
    batch: Optional[UnspecifiedLengthDimensionModel] = Field(None, title="Batch axis")


class ClassificationModelOutputSpecs(BaseModel):
    """
    Model returns a classification, i.e., a tensor of either logit or softmax
    scores for all classes.
    """

    class_names: Union[List[str], AutogeneratedClasses] = Field(
        ..., description="List of class names or number of classes", title="Class Names"
    )
    output_format: Union[DictOutputFormat, SingleOutputFormat] = Field(..., title="Output Format")
    dimensions: Optional[ClassificationScoreDimensionsModel] = Field(
        None, title="Classification Score Dimensions"
    )
    name: Literal["ClassificationOutput"] = Field("ClassificationOutput", title="Classification")


class SegmentationScoreDimensionsModel(BaseModel):
    """
    Segmentation Output has width, height, and class dimensions.
    """

    height: UnspecifiedLengthDimensionModel = Field(..., title="Height axis")
    width: UnspecifiedLengthDimensionModel = Field(..., title="Width axis")
    class_: UnspecifiedLengthDimensionModel = Field(..., title="Class axis")
    batch: Optional[UnspecifiedLengthDimensionModel] = Field(None, title="Batch axis")


class SegmentationModelOutputSpecs(BaseModel):
    """
    Model returns a segmentation map, i.e., a tensor of either logit or softmax
    scores for all classes for each pixel.
    """

    class_names: Union[List[str], AutogeneratedClasses] = Field(
        ..., description="List of class names or number of classes", title="Class Names"
    )
    output_format: Union[DictOutputFormat, SingleOutputFormat] = Field(..., title="Output Format")
    dimensions: SegmentationScoreDimensionsModel
    name: Literal["SegmentationOutput"] = Field("SegmentationOutput", title="Segmentation")


class DetectionDictOutputFormat(BaseModel):
    """
    Model outputs a dictionary of tensors.
    """

    name: Literal["DetectionDict"] = Field(
        "DetectionDict", title="Dictionary of Tensors for Detection"
    )
    scores_key: str = Field(
        ..., description="Key pointing to logit / softmax output.", title="Scores Key"
    )
    boxes_key: str = Field(
        ..., description="Key pointing to bounding box output.", title="Boxes Key"
    )


class DetectionScoreDimensionsModel(BaseModel):
    """
    DetectionScore Output.
    """

    proposal: UnspecifiedLengthDimensionModel = Field(..., title="Object proposal axis")
    class_: UnspecifiedLengthDimensionModel = Field(..., title="Class axis")
    batch: Optional[UnspecifiedLengthDimensionModel] = Field(None, title="Batch axis")


class BoundingBoxDimensionsModel(BaseModel):
    """
    Bounding Box Output.
    """

    proposal: UnspecifiedLengthDimensionModel = Field(..., title="Object proposal axis")
    coordinate: UnspecifiedLengthDimensionModel = Field(..., title="Coordinate axis")
    batch: Optional[UnspecifiedLengthDimensionModel] = Field(None, title="Batch axis")


class BoundingBoxFormatType(Enum):
    """
    Bounding box coordinate format.
    """

    xyxy = "xyxy"
    yxyx = "yxyx"
    xywh = "xywh"
    ccwh = "ccwh"


class DetectionModelOutputSpecs(BaseModel):
    """
    Output specification for models that return detections scores.
    """

    class_names: Union[List[str], AutogeneratedClasses] = Field(
        ..., description="List of class names or number of classes", title="Class Names"
    )
    output_format: DetectionDictOutputFormat
    dimensions: DetectionScoreDimensionsModel = Field(..., title="Detection Score Dimensions")
    box_dimensions: BoundingBoxDimensionsModel = Field(..., title="Bounding Box Dimensions")
    coordinate_format: BoundingBoxFormatType = Field(
        ..., description="Format of bounding box coordinates."
    )
    normalized_coordinates: bool = Field(
        ...,
        description="Whether or not the coordinates are normalized to [0, 1] range.",
        title="Normalized Coordinates",
    )
    post_processor: Optional[Any] = Field(None, title="Post Processor")
    name: str = Field("DetectionOutput", title="Detection")


class ImageModelContextSpecs(BaseModel):
    """
    Model for image input types.
    """

    name: Literal["ImageModelContext"] = Field("ImageModelContext", title="Computer Vision")
    input_specification: Union[GrayScaleImageInputSpecs, ColorImageInputSpecs] = Field(
        ..., title="Data Type"
    )
    output_specification: Union[
        ClassificationModelOutputSpecs, SegmentationModelOutputSpecs
    ] = Field(..., title="Task")


class NgramInputDimensionsModel(BaseModel):
    """
    Ngram input has optional batch dimension, index and feature dimensions are
    hardcoded.
    """

    batch: Optional[UnspecifiedLengthDimensionModel] = Field(
        None, description="Batch axis and length", title="Batch axis"
    )


class NoPreTokenizerSpecs(BaseModel):
    """
    Do not apply pre-tokenization.
    """

    name: Literal["NoPreTokenizer"] = Field("NoPreTokenizer", title="No Pre-Tokenizer")


class SplitPreTokenizerSpecs(BaseModel):
    """
    Split text input before tokenization.
    """

    name: Literal["SplitPreTokenizer"] = Field("SplitPreTokenizer", title="Split")
    convert_to_lower_case: bool = Field(
        True,
        description=(
            "Whether to convert the text input to lower case. If True, 'This is A sentence' ->"
            " 'this is a sentence'. If False, 'This is A Sentence' -> 'This is A sentence'. "
        ),
        title="Convert to Lower Case",
    )
    whitespace: bool = Field(
        True,
        description=(
            "Whether to separate the input text into words. If True, 'this is a sentence' ->"
            " 'this', 'is', 'a', 'sentence'. If False, 'this is a sentence' -> 'this is a"
            " sentence'. "
        ),
        title="Split by Whitespace",
    )
    keep_punctuation: bool = Field(
        True,
        description=(
            "Whether to keep punctuation (.,;:!?()) as separate tokens. If True, 'hello! this is a"
            " sentence.' -> 'hello', '!', 'this', 'is', 'a', 'sentence', '.'If False, 'hello! this"
            " is a sentence.' -> 'hello', 'this', 'is', 'a', 'sentence'"
        ),
        title="Keep Punctuation",
    )


class ByteLevelPreTokenizerSpecs(BaseModel):
    """
    Encoding that maps each byte value to a unique symbol.
    """

    name: Literal["ByteLevelPreTokenizer"] = Field("ByteLevelPreTokenizer", title="Byte Level")


class NoTokenizerSpecs(BaseModel):
    """
    Do not apply tokenization.
    """

    name: Literal["NoTokenizer"] = Field("NoTokenizer", title="No Tokenizer")


class WordLevelTokenizerSpecs(BaseModel):
    """
    A word-level tokenizer maps each token to an ID according to a vocabulary.
    """

    name: Literal["WordLevelTokenizer"] = Field("WordLevelTokenizer", title="Word Level")
    unk_token: str = Field(
        "[UNK]",
        description="Symbol to represent tokens that are not in the vocabulary.",
        title="Unknown Token",
    )
    vocab: str = Field(
        ...,
        description=(
            "The expected format is a JSON representation of a dictionary where the keys are the"
            " symbols in the vocabulary (strings) and the values are the corresponding IDs"
            ' (integers), e.g.: {"hello": 1, "world": 2, "[UNK]": 3}'
        ),
        title="Vocabulary",
    )


class BPETokenizerSpecs(BaseModel):
    """
    Byte-Pair Encoding (BPE) creates a 'merge list' and an according vocabulary
    by iteratively creating entries from merging the most frequent symbol
    pairs.

    During tokenization, tokens are first merged according to the 'merge
    list' and then mapped to IDs using the vocabulary.
    """

    name: Literal["BPETokenizer"] = Field("BPETokenizer", title="BPE Tokenizer")
    unk_token: str = Field(
        "<unk>",
        description="Symbol to represent tokens that are not in the vocabulary.",
        title="Unknown Token",
    )
    vocab: str = Field(
        ...,
        description=(
            "The expected format is a JSON representation of a dictionary where the keys are the"
            " symbols in the vocabulary (strings) and the values are the corresponding IDs"
            ' (integers), e.g.: {"hello": 1, "world": 2, "[UNK]": 3}'
        ),
        title="Vocabulary",
    )
    merges: str = Field(
        ...,
        description=(
            "Symbol pairs to be merged during Byte-Pair Encoding. The expected format is a text"
            " where each line contains one pair of symbols, i.e.:\na b\nc d\ne f\n"
        ),
        title="Merges",
    )


class NgramInputSpecs(BaseModel):
    """
    A string input.
    """

    name: Literal["Text"] = Field("Text", title="Text")
    batch_dim: BatchDim = Field("No Batch", title="Batch Axis Location")
    dimensions: Optional[NgramInputDimensionsModel] = None
    pre_tokenizer: Union[
        NoPreTokenizerSpecs, SplitPreTokenizerSpecs, ByteLevelPreTokenizerSpecs
    ] = Field(..., title="Pre-Tokenizer")
    tokenizer: Union[NoTokenizerSpecs, WordLevelTokenizerSpecs, BPETokenizerSpecs] = Field(
        ..., title="Tokenizer"
    )


class TextModelContextSpecs(BaseModel):
    """
    Model for text input types.
    """

    name: Literal["TextModelContext"] = Field(
        "TextModelContext", title="Natural Language Processing"
    )
    input_specification: NgramInputSpecs = Field(..., title="Data Type")
    output_specification: ClassificationModelOutputSpecs = Field(..., title="Task")


class MLModelResponse(BaseModel):
    """
    MLModel response model.
    """

    id: int = Field(..., title="Id")
    name: str = Field(..., title="Name")
    versions: List[MLModelVersionResponse] = Field(..., title="Versions")
    framework: FrameworkType
    context: Union[ImageModelContextSpecs, TextModelContextSpecs] = Field(..., title="Context")


class ListMLModelResponse(BaseModel):
    """
    List MLModel response model.
    """

    ml_models: List[MLModelResponse] = Field(..., title="Ml Models")


class TargetClassInput(BaseModel):
    """
    Union of str/int used as an input.
    """

    name: Literal["TargetClassInput"] = Field(
        "TargetClassInput",
        description=(
            "Specifies the target class used by an algorithm either by `index` (an integer value"
            " starting with 0) or by taking the argmax of the model prediction."
        ),
        title="Target Class",
    )
    value: Union[int, Literal["argmax"]] = Field(..., title="Value")


class IdentifierInput(BaseModel):
    """
    An entity identifier.
    """

    name: Literal["IdentifierInput"] = Field(
        "IdentifierInput",
        description='Identifier (ID) for a resource such as "Dataset" and "Pipeline".',
        title="Resource ID",
    )
    value: int = Field(..., title="Value")


class UserProvidedContext(BaseModel):
    pipeline_node_id: int = Field(..., title="Pipeline Node Id")
    context_name: str = Field(..., title="Context Name")
    value: Union[TargetClassInput, IdentifierInput] = Field(..., title="Value")


class CreatePipelineRunRequest(BaseModel):
    pipeline_id: int = Field(..., title="Pipeline Id")
    context: List[UserProvidedContext] = Field(..., title="Context")


class PipelineRunState(Enum):
    """
    Life cycle of a pipeline run node.
    """

    PENDING = "PENDING"
    STOPPED = "STOPPED"
    RUNNING = "RUNNING"
    SUCCESS = "SUCCESS"
    FAILED = "FAILED"


class PipelineRunNodeResponse(BaseModel):
    id: int = Field(..., title="Id")
    state: PipelineRunState


class NamedEntity(BaseModel):
    id: int = Field(..., title="Id")
    name: str = Field(..., title="Name")


class PipelineRunResponse(BaseModel):
    id: int = Field(..., title="Id")
    nodes: List[PipelineRunNodeResponse] = Field(..., title="Nodes")
    ml_model: Optional[NamedEntity] = None
    ml_model_version: Optional[NamedEntity] = None
    dataset: Optional[NamedEntity] = None
    subset: Optional[NamedEntity] = None
    pipeline: Optional[NamedEntity] = None
    state: PipelineRunState
    started_at: Optional[str] = Field(None, title="Started At")
    finished_at: Optional[str] = Field(None, title="Finished At")
    index_in_pipeline: int = Field(..., title="Index In Pipeline")


class PipelineRunListResponse(BaseModel):
    pipeline_runs: List[PipelineRunResponse] = Field(..., title="Pipeline Runs")


class RequiredContextDescription(BaseModel):
    pipeline_node_id: int = Field(..., title="Pipeline Node Id")
    context_name: str = Field(..., title="Context Name")
    context_type: Dict[str, Any] = Field(..., title="Context Type")


class RequiredContextResponse(BaseModel):
    items: List[RequiredContextDescription] = Field(..., title="Items")


class ReportMethod(BaseModel):
    method_name: str = Field(..., title="Method Name")
    param_string: str = Field(..., title="Param String")
    pipeline_node_id: int = Field(..., title="Pipeline Node Id")


class ReportObservation(BaseModel):
    id: int = Field(..., title="Id")
    name: str = Field(..., title="Name")
    thumbnail_url: str = Field(..., title="Thumbnail Url")


class ReportEntry(BaseModel):
    method_name: str = Field(..., title="Method Name")
    param_string: str = Field(..., title="Param String")
    plot_url: str = Field(..., title="Plot Url")
    observation: ReportObservation


class ReportMethodResponse(BaseModel):
    report_target: ReportMethod
    artifacts: List[ReportEntry] = Field(..., title="Artifacts")


class ReportObservationResponse(BaseModel):
    report_target: ReportObservation
    artifacts: List[ReportEntry] = Field(..., title="Artifacts")


class ReportAverageRow(BaseModel):
    method: ReportMethod
    metric: ReportMethod
    metric_value: float = Field(..., title="Metric Value")


class ObservationRiskScore(BaseModel):
    observation: ReportObservation
    risk_score: float = Field(..., title="Risk Score")


class ReportResponse(BaseModel):
    adversaries: List[ReportAverageRow] = Field(..., title="Adversaries")
    corruptions: List[ReportAverageRow] = Field(..., title="Corruptions")
    backdoor: List[ObservationRiskScore] = Field(..., title="Backdoor")
    explanations: List[ReportAverageRow] = Field(..., title="Explanations")
    observations: List[ReportObservation] = Field(..., title="Observations")
    methods: List[ReportMethod] = Field(..., title="Methods")


class SubsetResponse(BaseModel):
    id: int = Field(..., title="Id")
    name: str = Field(..., title="Name")
    observation_ids: List[int] = Field(..., title="Observation Ids")


class SubsetCreateRequest(BaseModel):
    name: str = Field(..., title="Name")
    dataset_name: str = Field(..., title="Dataset Name")
    observation_ids: List[int] = Field(..., title="Observation Ids")


class SubsetUpdateRequest(BaseModel):
    name: str = Field(..., title="Name")
    observation_ids: List[int] = Field(..., title="Observation Ids")


class ObservationResponse(BaseModel):
    id: int = Field(..., title="Id")
    type: str = Field(..., title="Type")
    file_name: str = Field(..., title="File Name")
    file_url: Optional[str] = Field(None, title="File Url")


class DatasetResponse(BaseModel):
    id: int = Field(..., title="Id")
    name: str = Field(..., title="Name")
    type: str = Field(..., title="Type")
    observation_ids: List[int] = Field(..., title="Observation Ids")
    subsets: List[SubsetResponse] = Field(..., title="Subsets")


class ObservationType(Enum):
    """
    Identification of the type of an observation.

    Required for parsing an observation into a core-object.
    """

    NGRAM = "NGRAM"
    COLOR_IMAGE = "COLOR_IMAGE"
    GREY_SCALE_IMAGE = "GREY_SCALE_IMAGE"


class DatasetUploadRequest(BaseModel):
    name: str = Field(..., title="Name")
    type: ObservationType


class Report2Request(BaseModel):
    """
    Model for the request to the only report 2.0 endpoint.
    """

    model: str = Field(..., title="Model")
    model_versions: List[str] = Field(..., title="Model Versions")
    dataset: str = Field(..., title="Dataset")
    subset: str = Field(..., title="Subset")
    metrics: List[str] = Field(..., title="Metrics")


class ReportPlotRecipes(BaseModel):
    """
    Class containing all report plot recipes represented as dictionaries.
    """

    data_centric_csr: Dict[str, Any] = Field(..., title="Data Centric Csr")
    model_centric_csr: Dict[str, Any] = Field(..., title="Model Centric Csr")
    attack_centric_csr: Dict[str, Any] = Field(..., title="Attack Centric Csr")


class ModelNormStats(BaseModel):
    """
    Pydantic model containing the statistics for a model version and distance
    metric.
    """

    impact: float = Field(..., title="Impact")
    vulnerability: float = Field(..., title="Vulnerability")
    p_damage: float = Field(..., title="P Damage")


class ReportStats(BaseModel):
    """
    Pydantic model containing the summary statistics for the data-centric view.
    """

    data_centric_stats: Dict[str, Dict[str, ModelNormStats]] = Field(
        ..., title="Data Centric Stats"
    )


class Report2Response(BaseModel):
    """
    Server response for the report endpoint.
    """

    data: Dict[str, List] = Field(..., title="Data")
    plot_recipes: ReportPlotRecipes
    stats: ReportStats


class _ModelCompilation(BaseModel):
    ml_model_version_response: MLModelVersionResponse
    list_ml_model_version_response: ListMLModelVersionResponse
    ml_model_response: MLModelResponse
    list_ml_model_response: ListMLModelResponse
    create_pipeline_run_request: CreatePipelineRunRequest
    pipeline_run_response: PipelineRunResponse
    pipeline_run_list_response: PipelineRunListResponse
    required_context_response: RequiredContextResponse
    report_method_response: ReportMethodResponse
    report_observation_response: ReportObservationResponse
    report_response: ReportResponse
    subset_response: SubsetResponse
    subset_create_request: SubsetCreateRequest
    subset_update_request: SubsetUpdateRequest
    observation_response: ObservationResponse
    dataset_response: DatasetResponse
    dataset_request: DatasetUploadRequest
    report_2_request: Report2Request
    report_2_response: Report2Response
